<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title> =^..^= MEH (Posts about variability)</title><link>https://chow1026.github.io/</link><description></description><atom:link href="https://chow1026.github.io/tags/variability.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 08 Aug 2017 01:30:35 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Descriptive Statistics - Variability</title><link>https://chow1026.github.io/course-notes/descriptive-statistics/lesson-4/</link><dc:creator>cHoWy</dc:creator><description>&lt;div&gt;&lt;h3&gt;Lesson 4: Variability&lt;/h3&gt;
&lt;h4&gt;General Ideas of Variability&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Range&lt;/strong&gt;: The maximum data point minus the minimum data point.  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wide Spread&lt;/strong&gt;: The data set has shorter and wider distribution.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: When a data is more consistent, it forms taller and narrower distribution.  &lt;/li&gt;
&lt;li&gt;Outlier(s) usually widen the range of distribution and INCREASES variability.  Statisticians usually cut off outliers.&lt;/li&gt;
&lt;li&gt;1st Quartile, &lt;strong&gt;\( Q_{1} \)&lt;/strong&gt;, is the 25% of the distribution, while 3rd Quartile, &lt;strong&gt;\( Q_{3} \)&lt;/strong&gt;, is the 75% of the distribution.  2nd Quartile, also known as Median, is the 50% of the distribution.  &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interquartile Range&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;\(IQR =  Q_{3} - Q_{1} \)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Facts about &lt;strong&gt;\(IQR \)&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;About 50% of data lies between IQR.&lt;/li&gt;
&lt;li&gt;IQR may or may not be affected by every value in the dataset.  &lt;/li&gt;
&lt;li&gt;IQR is NOT affected by outliers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A data point is considered an outlier if any of the below is true:&lt;ul&gt;
&lt;li&gt;\[ x_{outlier} &amp;lt; Q_{1} - 1.5*IQR \]&lt;/li&gt;
&lt;li&gt;\[ x_{outlier} &amp;gt; Q_{3} - 1.5*IQR \]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Box Plots&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Key Elements of Box Plots:&lt;ul&gt;
&lt;li&gt;Max, Min (two handles of the box)&lt;/li&gt;
&lt;li&gt;\( Q_{1} \), \( Q_{3} \), \( Q_{2} \) (aka Median) forms the box, with Median in the center "splitting" the box.&lt;/li&gt;
&lt;li&gt;Outliers, drawn as dots next to /outside of Max and/or Min.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Box plots sometimes don't tell about the distribution model of data.  The box plot for normal, bimodal, or uniform distribution are the same.&lt;/li&gt;
&lt;li&gt;Although usually the mean lies between \( Q_{1} \) and \( Q_{3} \), it may lie outside of it, if there are outliers.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Measuring Variability&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;To measure variability, we find the average distance between each data value and the mean.&lt;/li&gt;
&lt;li&gt;\[ Deviation, \delta = x_{i} - \bar{x} \]&lt;/li&gt;
&lt;li&gt;Average Deviation, \(\bar{\delta}\):&lt;ul&gt;
&lt;li&gt;\[ \bar{\delta} = \frac{ \sum_{i=0}^N{  \lvert{x_{i} - \bar{x} } \rvert }}{N}\]&lt;/li&gt;
&lt;li&gt;\[ \bar{\delta} = \frac{ \sum_{i=0}^N{\lvert\bar{x} - x_{i}\rvert}}{N} \]&lt;/li&gt;
&lt;li&gt;\[ \bar{\delta} = \sum_{i=0}^N{\frac{ \lvert \bar{x} - x_{i} \rvert }{N}} \]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Squared Deviation, \( \delta^2 \):&lt;ul&gt;
&lt;li&gt;\[ \delta^2 = {\lvert{x_{i} - \bar{x} } \rvert}^2 \]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sum of Squares, \( \sum_{i=0}^N(\delta^2) \), aka \( SS \):&lt;ul&gt;
&lt;li&gt;\[ SS = \sum_{i=0}^N{({x_{i} - \bar{x}})^2} \]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Variance, \( \sigma^2 \), which is simply the Mean of \( SS \), \( \bar{SS} \) is:&lt;ul&gt;
&lt;li&gt;\[ \sigma^2 = \frac{\sum_{i=0}^N{{({x_{i} - \bar{x}})}^2}}{N} \]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Standard Deviation, \( \sigma \), is the square root of variance.  &lt;ul&gt;
&lt;li&gt;\[ \sigma = \sqrt{\frac{\sum_{i=0}^N{{({x_{i} - \bar{x}})}^2}}{N}} \]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why Standard Deviation? In a perfectly normal distribution where mean equals to median equals to mode, 68% of the data values would fall between \( -1 \sigma \) and \( +1 \sigma \), 95% of the data values will fall between \( -2 \sigma \) and \( +2 \sigma \)&lt;/li&gt;
&lt;li&gt;When a sample is taken from a population, the sample standard deviation is usually smaller than true standard deviation, \( \sigma \), of the population.  To correct that, we apply Bessel's Correction.  The corrected/estimation sample standard deviation, denoted as \( s \), and corresponding variance, will have the formulas below:&lt;ul&gt;
&lt;li&gt;\[ s^2 = \frac{\sum_{i=0}^N{{({x_{i} - \bar{x}})}^2}}{N -1} \]&lt;/li&gt;
&lt;li&gt;\[ s = \sqrt{\frac{\sum_{i=0}^N{{({x_{i} - \bar{x}})}^2}}{N-1}} \]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;</description><category>descriptive-statistics</category><category>variability</category><guid>https://chow1026.github.io/course-notes/descriptive-statistics/lesson-4/</guid><pubDate>Wed, 17 Aug 2016 03:29:46 GMT</pubDate></item></channel></rss>