<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title> =^..^= MEH (hypothsis-testing)</title><link>https://chowy1026.github.io/</link><description></description><atom:link rel="self" href="https://chowy1026.github.io/tags/hypothsis-testing.xml" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Fri, 30 Sep 2016 07:42:42 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Inferential Statistics - Hypothesis Testing</title><link>https://chowy1026.github.io/course-notes/inferential-statistics/lesson-9/</link><dc:creator>cHoWy</dc:creator><description>&lt;div&gt;&lt;h2&gt;Hypothesis Test and Alpha Levels&lt;/h2&gt;
&lt;p&gt;A Hypothesis test is used to test a claim that someone has about an observation may be different from the known population parameter.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Alpha level&lt;/strong&gt; (&lt;strong&gt;\( \alpha \)&lt;/strong&gt;) of a hypothesis test helps us determine the critical region of a distribution.  Refer to &lt;a href="https://chowy1026.github.io/course-notes/inferential-statistics/lesson-9/#critical-region"&gt;Critical Regions&lt;/a&gt; below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Null Hypothesis&lt;/strong&gt; is always an equality.  It is the claim we are trying to provide evidence &lt;em&gt;against&lt;/em&gt;.  We commonly write the null hypothesis as one of the following:
\[  H_{0} : \mu_{0} = \mu\\  H_{0} : \mu_{0} \ge \mu\\  H_{0} : \mu_{0} \le \mu \]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Null Hypothesis&lt;/strong&gt; is result we are checking against the claim.  This is always some kind of inequality.  We commonly write the alternative hypothesis as one of the following:
\[  case\;a &amp;gt;&amp;gt; H_{0} : \mu_{0} \neq \mu\\  case\;b &amp;gt;&amp;gt; H_{0} : \mu_{0} \gt \mu\\  case\;c &amp;gt;&amp;gt; H_{0} : \mu_{0} \lt \mu \]&lt;/p&gt;
&lt;p&gt;If we know which direction we are checking against the claim, use case b or case c, else we typically use case a.  Case a is a two tailed test, while case b and case c are one tailed tests.  Read more on this &lt;a href="https://chowy1026.github.io/course-notes/inferential-statistics/lesson-9/#one-tailed-two-tailed"&gt;below&lt;/a&gt;.  &lt;/p&gt;
&lt;h2&gt;&lt;a id="critical-region" name="critical-region"&gt;&lt;/a&gt;Critical Regions&lt;/h2&gt;
&lt;p&gt;When it comes to constructing a hypothesis test, it is best to choose a significant level before the test is performed.  The results of the test can be reported as significant a certain critical level, but it is important that you are not "fishing" for results before seeing the results in your sample.  For additional readings on Hypothesis Testing, here is an &lt;a href="http://blog.minitab.com/blog/adventures-in-statistics/understanding-hypothesis-tests:-significance-levels-alpha-and-p-values-in-statistics" title="Hypothesis Testing"&gt;article&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;The corresponding Z-critical values, \( Z_{critical} \) at each \( \alpha \) level for one-tailed test and two-tailed test respectively:
\[
\begin{array}{c|cc}
\alpha &amp;amp; \text{one-tailed} &amp;amp; \text{two-tailed} \\
\hline
0.05 &amp;amp; 1.67 \; or\; -1.67 &amp;amp; \pm 1.96 \\
0.01 &amp;amp; 2.32 \; or\; -2.32 &amp;amp; \pm 2.57 \\
0.001 &amp;amp; 3.08 \; or\; -3.08 &amp;amp; \pm 3.27
\end{array}
\]&lt;/p&gt;
&lt;p&gt;If we get a sample mean in the critical region, then we decide that most likely those sample means by chance.  The \( Z_{critical} \) values are the same that we used to calculate confidence intervals.  &lt;/p&gt;
&lt;p&gt;When we do statistical test, we'll set our own criteria for making a decision (in other words, we'll choose an alpha level). Then we decide if the probability of obtaining that sample mean is less than the alpha level (ie. sample means fall in the critical region, and \(Z\) is greater than \(Z_{critical}\)). Then if there is an evidence of an effect (of the intervention).&lt;/p&gt;
&lt;p&gt;Note that we &lt;strong&gt;CANNOT prove&lt;/strong&gt; if a hypothesis is true.  We can only obtain evidence to reject the null hypothesis.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:
A null hypothesis says "Most (more than 50%) dogs have four legs." and the alternative hypothesis says "Most dogs have less than four legs."&lt;/p&gt;
&lt;p&gt;In a sample of 10 dogs, there are 6 dogs with less than four legs.  &lt;/p&gt;
&lt;p&gt;In this case we are taking 50% as significance level.  We are able to reject the null hypothesis based on this.  Under a typical statistical test (such as using a 5% significance level), this sample data would be evidence against null hypothesis, but not necessarily enough evidence/information to reject the null hypothesis.  &lt;/p&gt;
&lt;p&gt;However, if the definition of null hypothesis was changed to indicate 70% of dogs have four legs, then our current evidence would be enough to reject the null hypothesis to reject the null hypothesis at a 5% significance level.  &lt;/p&gt;
&lt;h2&gt;&lt;a id="one-tailed-two-tailed" name="one-tailed-two-tailed"&gt;&lt;/a&gt; One Tailed and Two Tailed&lt;/h2&gt;
&lt;p&gt;Take a hypothesis test:
\[
    H_{0}:
    \begin{cases}
      \mu = \mu_{I},  &amp;amp; \mu_{I} \text{is post intervention}
    \end{cases} \\
    H_{A}:
    \begin{cases}
      \mu \lt \mu_{I},  &amp;amp; \text{right one-tailed, with } \mu_{I} \text{ greater than } \mu \\
      \mu \gt \mu_{I},  &amp;amp; \text{left one-tailed, with } \mu_{I} \text{ less than } \mu \\
      \mu \neq \mu_{I},  &amp;amp; \text{right one-tailed, with } \mu_{I} \text{ greater or less than } \mu
    \end{cases}
\]&lt;/p&gt;
&lt;p&gt;We choose a one-tailed, or directional hypothesis test when we predict a direction of the treatment effect.  Alternatively, when we do not predict the direction of the treatment, we choose the two-tailed or non-directional test.  In general we use two-tailed because it is more conservative.  We are less likely to reject the null when it is true.  It also prevents us from mistaking the wrong direction of the effect.  &lt;/p&gt;
&lt;h2&gt;Decision Errors&lt;/h2&gt;
&lt;p&gt;There are two types of Hypothesis Decision Errors:
&lt;strong&gt;Type I error&lt;/strong&gt;: is when you reject the null when the null hypothesis is actually true.&lt;br&gt;
&lt;strong&gt;Type II error&lt;/strong&gt;: is when you fail to reject the null when the null hypothesis is actually false.  &lt;/p&gt;&lt;/div&gt;</description><category>hypothsis-testing</category><category>inferential-statistics</category><guid>https://chowy1026.github.io/course-notes/inferential-statistics/lesson-9/</guid><pubDate>Tue, 20 Sep 2016 09:36:10 GMT</pubDate></item></channel></rss>