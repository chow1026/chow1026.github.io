<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title> =^..^= MEH (sampling distribution)</title><link>https://chowy1026.github.io/</link><description></description><atom:link rel="self" type="application/rss+xml" href="https://chowy1026.github.io/tags/sampling-distribution.xml"></atom:link><language>en</language><lastBuildDate>Mon, 22 Aug 2016 03:19:08 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Descriptive Statistics - Sampling Distributions</title><link>https://chowy1026.github.io/course-notes/descriptive-statistics/lesson-7/</link><dc:creator>cHoWy</dc:creator><description>&lt;div&gt;&lt;h3&gt;Lesson 7: Central Limit Theorem&lt;/h3&gt;
&lt;p&gt;The Central Limit Theorem is used to help us understand the following facts regardless of
whether the population distribution is normal or not:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the mean of the sample means is the same as the population mean&lt;/li&gt;
&lt;li&gt;the standard deviation of the sample means is always equal to the standard error (i.e.
\[ SE = \frac{\sigma}{ \sqrt{n}} \]&lt;/li&gt;
&lt;li&gt;the distribution of sample means will become increasingly more normal as the sample size,
n, increases.&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;</description><category>descriptive-statistics</category><category>sampling distribution</category><guid>https://chowy1026.github.io/course-notes/descriptive-statistics/lesson-7/</guid><pubDate>Fri, 19 Aug 2016 02:36:43 GMT</pubDate></item></channel></rss>