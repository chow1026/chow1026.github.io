<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title> =^..^= MEH ·  =^..^= MEH (old posts, page 4) </title>
<link href="assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="assets/css/poole.css" rel="stylesheet" type="text/css">
<link href="assets/css/hyde.css" rel="stylesheet" type="text/css">
<link href="assets/css/code.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700%7CAbril+Fatface">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="https://chowy1026.github.io/index-4.html">
<link rel="icon" href="images/favicon.png" sizes="64x64">
<link rel="icon" href="images/icon_512x512.png" sizes="512x512">
<link rel="prev" href="index-5.html" type="text/html">
<link rel="next" href="index-3.html" type="text/html">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: true
            },
            displayAlign: 'center', // Change this to 'left' to left equations.
            "HTML-CSS": {
                styles: {'.MathJax_Display': {"margin": 0}}
            }
        });
    </script><script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body class="test">
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

    <div class="sidebar">
        <div class="container sidebar-sticky">
            <div class="sidebar-about">
              <h1>
                <a href="https://chowy1026.github.io/">
                      <h1 id="brand"><a href="https://chowy1026.github.io/" title=" =^..^= MEH" rel="home">

        <span id="blog-title"> =^..^= MEH</span>
    </a></h1>

                </a>
              </h1>
                <p class="lead"></p>

            </div>
                <nav id="menu" role="navigation" class="sidebar-nav"><a class="sidebar-nav-item" href="posts/index.html">Articles</a>
        <a class="sidebar-nav-item" href="course-notes/index.html">Course Notes</a>
        <a class="sidebar-nav-item" href="links/index.html">Links</a>
        <a class="sidebar-nav-item" href="books/index.html">Books</a>
        <a class="sidebar-nav-item" href="archives/archives.html">Archives</a>
        <a class="sidebar-nav-item" href="tags.html">Tags</a>
    
    
    </nav><footer id="footer"><p class="footer">
              <span class="icon_row">

                <a href="mailto:chowy1026@gmail.com">
                  <img class="social_icon" src="images/envelope1.png" title="email" width="24"></a> ·
                <!--<a href="">
                  <img class="social_icon" src="/images/twitter-black-shape1.png" title="twitter" width="24" /></a> &middot;-->
                <a href="https://github.com/chowy1026/">
                  <img class="social_icon" src="images/github-character1.png" title="github" width="24"></a>
              </span>
              <br><br><span class="copyright">
              
Contents © 2017 by <a href="mailto:chowy1026@gmail.com">cHoWy</a> ·
Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a> <br><a href="http://hyde.getpoole.com" target="_blank">Hyde</a> theme by <a href="https://twitter.com/mdo" target="_blank">@mdo</a>

            </span>
            </p>
            
        </footer>
</div>
    </div>

    <div class="content container" id="content">
    
<div class="post">
    <article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="course-notes/machine-learning/05-supervised_learning-adaboost/" class="u-url">Supervised Learning - Adaboost</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-04-04T14:23:07+08:00" title="2017-04-04 14:23">2017-04-04 14:23</time></span>
        </div>
    </header><div class="e-content entry-content">
    <p>Write your post here.</p>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="course-notes/machine-learning/05-supervised_learning-random_forest/" class="u-url">Supervised Learning - Random Forest</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-04-04T14:22:30+08:00" title="2017-04-04 14:22">2017-04-04 14:22</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Random forests or random decision forests are an <a href="https://en.wikipedia.org/wiki/Ensemble_learning" title="Ensemble Learning">ensemble learning</a> method for <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical Classification">classification</a>, regression and other tasks, that operate by constructing a multitude of <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision Tree Learning">decision tree</a>s at training time and outputting the class that is the <a href="https://en.wikipedia.org/wiki/Mode_(statistics)" title="Mode (Statistics)">mode</a> of the classes (classification) or mean prediction (<a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression Analysis">regression</a>) of the individual trees. Random decision forests correct for decision trees' habit of <a href="https://en.wikipedia.org/wiki/Overfitting" title="Overfitting">overfitting</a> to their training set.</p>
<p>The first algorithm for random decision forests was created by Tin Kam Ho using the <a href="https://en.wikipedia.org/wiki/Random_subspace_method" title="Random Subspace">random subspace method</a>, which, in Ho's formulation, is a way to implement the "<a href="https://en.wikipedia.org/w/index.php?title=Stochastic_discrimination&amp;redirect=no" title="Stochastic Discrimination (Redirects to https://en.wikipedia.org/wiki/Statistical_classification)">stochastic discrimination</a>" approach to classification proposed by Eugene Kleinberg.    </p>
<p>An extension of the algorithm was developed by Leo Breiman and Adele Cutler, and "Random Forests" is their trademark.  The extension combines Breiman's "<a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" title="Bagging (Redirects to Bootstrap Aggregating)">bagging</a>" idea and random selection of features, introduced first by Ho and later independently by Amit and Geman in order to construct a collection of decision trees with controlled variance.</p>
<h2>History</h2>
<p>The general method of random decision forests was first proposed by Ho in 1995, who established that forests of trees splitting with oblique hyperplanes, if randomly restricted to be sensitive to only selected feature dimensions, can gain accuracy as they grow without suffering from overtraining. A subsequent work along the same lines  concluded that other splitting methods, as long as they are randomly forced to be insensitive to some feature dimensions, behave similarly. Note that this observation of a more complex classifier (a larger forest) getting more accurate nearly monotonically is in sharp contrast to the common belief that the complexity of a classifier can only grow to a certain level of accuracy before being hurt by overfitting. The explanation of the forest method's resistance to overtraining can be found in Kleinberg's theory of stochastic discrimination.  </p>
<p>The early development of Breiman's notion of random forests was influenced by the work of Amit and Geman  who introduced the idea of searching over a random subset of the available decisions when splitting a node, in the context of growing a single <a href="https://en.wikipedia.org/wiki/Decision_tree" title="Decision Tree">tree</a>. The idea of random subspace selection from Ho was also influential in the design of random forests. In this method a forest of trees is grown, and variation among the trees is introduced by projecting the training data into a randomly chosen <a href="https://en.wikipedia.org/wiki/Linear_subspace" title="Linear Subspace">subspace</a> before fitting each tree or each node. Finally, the idea of randomized node optimization, where the decision at each node is selected by a randomized procedure, rather than a deterministic optimization was first introduced by Dietterich.</p>
<p>The introduction of random forests proper was first made in a paper by Leo Breiman.  This paper describes a method of building a forest of uncorrelated trees using a CART like procedure, combined with randomized node optimization and bagging. In addition, this paper combines several ingredients, some previously known and some novel, which form the basis of the modern practice of random forests, in particular:     <br>
- Using <a href="https://en.wikipedia.org/wiki/Out-of-bag_error" title="Out of Bag Error">out-of-bag error</a> as an estimate of the <a href="https://en.wikipedia.org/wiki/Generalization_error" title="Generalization Error">generalization error</a>.    <br>
- Measuring variable importance through permutation.     </p>
<p>The report also offers the first theoretical result for random forests in the form of a bound on the generalization error which depends on the strength of the trees in the forest and their correlation.</p>
<h2>Algorithm</h2>
<h3>Preliminaries: decision tree learning</h3>
<p><em>Main article: <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision Tree Learning">Decision tree learning</a></em>    <br>
Decision trees are a popular method for various machine learning tasks. Tree learning "come[s] closest to meeting the requirements for serving as an off-the-shelf procedure for data mining", say Hastie et al., because it is invariant under scaling and various other transformations of feature values, is robust to inclusion of irrelevant features, and produces inspectable models. However, they are seldom accurate.</p>
<p>In particular, trees that are grown very deep tend to learn highly irregular patterns: they overfit their training sets, i.e. <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" title="Bias Variance Tradeoff">have low bias, but very high variance</a>. Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance.[3]:587–588 This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance of the final model.</p>
<h3>Tree bagging</h3>
<p><em>Main article: <a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" title="Bagging (Redirects to Bootstrap Aggregating)">Bootstrap aggregating</a></em>     <br>
The training algorithm for random forests applies the general technique of bootstrap aggregating, or bagging, to tree learners.  Given a training set \(X = x1, ..., xn\) with responses \(Y = y1, ..., yn\), bagging repeatedly (\(B\) times) selects a random sample with replacement of the training set and fits trees to these samples:</p>
<pre class="code literal-block"><span></span>For \\(b\\) = 1, ..., \\(B\\):      
    1. Sample, with replacement, \\(B\\) training examples from \\(X, Y\\); call these \\(Xb, Yb\\).       
    2. Train a decision or regression tree fb on \\(Xb, Yb\\).
</pre>


<p>After training, predictions for unseen samples \(x'\) can be made by averaging the predictions from all the individual regression trees on \(x'\):  <br>
\[
\hat f = \frac{1}{B}\;\sum_{b=1}^B\,f_b(x')
\]     </p>
<p>or by taking the majority vote in the case of decision trees.</p>
<p>This bootstrapping procedure leads to better model performance because it <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" title="Bias Variance Tradeoff">decreases the variance of the model, without increasing the bias</a>. This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees (or even the same tree many times, if the training algorithm is deterministic); bootstrap sampling is a way of de-correlating the trees by showing them different training sets.</p>
<p>The number of samples/trees, \(B\), is a free parameter. Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees \(B\) can be found using cross-validation, or by observing the <a href="https://en.wikipedia.org/wiki/Out-of-bag_error" title="Out of Bag Error">out-of-bag error</a>: the mean prediction error on each training sample \(x_i\), using only the trees that did not have \(x_i\) in their bootstrap sample.  The training and test error tend to level off after some number of trees have been fit.</p>
<h3>From bagging to random forests</h3>
<p><em>Main article: <a href="https://en.wikipedia.org/wiki/Random_subspace_method" title="Random Subspace">Random subspace method</a></em>   <br>
The above procedure describes the original bagging algorithm for trees. Random forests differ in only one way from this general scheme: they use a modified tree learning algorithm that selects, at each candidate split in the learning process, a <a href="https://en.wikipedia.org/wiki/Random_subspace_method" title="Random Subspace">random subset</a> of the features. This process is sometimes called "feature bagging". The reason for doing this is the correlation of the trees in an ordinary bootstrap sample: if one or a few features are very strong predictors for the response variable (target output), these features will be selected in many of the \(B\) trees, causing them to become correlated. An analysis of how bagging and random subspace projection contribute to accuracy gains under different conditions is given by Ho.</p>
<p>Typically, for a classification problem with \(p\) features, \(\sqrt{\,p}\) (rounded down) features are used in each split.  For regression problems the inventors recommend \(p\)/3 (rounded down) with a minimum node size of 5 as the default.</p>
<h3>ExtraTrees</h3>
<p>Adding one further step of randomization yields extremely randomized trees, or ExtraTrees. These are trained using bagging and the random subspace method, like in an ordinary random forest, but additionally the top-down splitting in the tree learner is randomized. Instead of computing the locally optimal feature/split combination (based on, e.g., <a href="https://en.wikipedia.org/wiki/Information_gain" title="Information Gain">information gain</a> or the <a href="https://en.wikipedia.org/wiki/Gini_impurity" title="Gini Impurity">Gini impurity</a>), for each feature under consideration, a random value is selected for the split. This value is selected from the feature's empirical range (in the tree's training set, i.e., the bootstrap sample).  </p>
<h2>Other Useful Reference:</h2>
<ul>
<li>
<a href="https://en.wikipedia.org/wiki/Random_tree" title="Random Tree">Random Tree</a>    </li>
<li>
<a href="https://en.wikipedia.org/wiki/Predictive_inference" title="Predictive Inference">Predictive Inference</a>    </li>
</ul>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="course-notes/machine-learning/03-supervised_learning-decision_tree/" class="u-url">Supervised Learning - Decision Tree</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-04-03T17:14:29+08:00" title="2017-04-03 17:14">2017-04-03 17:14</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>A <a href="https://en.wikipedia.org/wiki/Decision_tree" title="Decision Tree">decision tree</a> is a <a href="https://en.wikipedia.org/wiki/Decision_support_system" title="Decision Support System">decision support</a> tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm.</p>
<p>Decision trees are commonly used in <a href="https://en.wikipedia.org/wiki/Operations_research" title="Operations Research">operations research</a>, specifically in <a href="https://en.wikipedia.org/wiki/Decision_analysis" title="Decision Analysis">decision analysis</a>, to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.</p>
<h2>Overview</h2>
<p>A decision tree is a <a href="https://en.wikipedia.org/wiki/Flowchart" title="Flowchart">flowchart</a>-like structure in which each internal node represents a "test" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.</p>
<p>In <a href="https://en.wikipedia.org/wiki/Decision_analysis" title="Decision Analysis">decision analysis</a>, a decision tree and the closely related <a href="https://en.wikipedia.org/wiki/Influence_diagram" title="Influence Diagram">influence diagram</a> are used as a visual and analytical decision support tool, where the expected values (or expected utility) of competing alternatives are calculated.</p>
<p>A decision tree consists of three types of nodes:</p>
<p>Decision nodes – typically represented by squares
Chance nodes – typically represented by circles
End nodes – typically represented by triangles
Decision trees are commonly used in operations research and <a href="https://en.wikipedia.org/wiki/Operations_management" title="Operation Management">operations management</a>. If, in practice, decisions have to be taken online with no recall under incomplete knowledge, a decision tree should be paralleled by a probability model as a best choice model or online selection model algorithm. Another use of decision trees is as a descriptive means for calculating <a href="https://en.wikipedia.org/wiki/Conditional_probability" title="Conditional Probability">conditional probabilities</a>.</p>
<p><a href="https://en.wikipedia.org/wiki/Decision_tree" title="Decision Tree">Decision trees</a>, <a href="https://en.wikipedia.org/wiki/Influence_diagram" title="Influence Diagram">influence diagrams</a>, <a href="https://en.wikipedia.org/wiki/Utility#Utility_functions" title="Utility Functions">utility functions</a>, and other decision analysis tools and methods are taught to undergraduate students in schools of business, health economics, and public health, and are examples of operations research or management science methods.</p>
<h2>Data Impurity and Entropy</h2>
<p>A decision tree is built top-down from a root node and involves partitioning the data into subsets that contain instances with similar values (homogenous). ID3 algorithm uses entropy to calculate the homogeneity of a sample. If the sample is completely homogeneous the entropy is zero and if the sample is an equally divided it has entropy of one.
\begin{aligned}
p &amp;= 0.5\\
\therefore\; q &amp;= 1 - p\\
&amp;= 0.5\\
\end{aligned}</p>
<p>\begin{aligned}
Entropy &amp;= -p\,log_2p -q\,log_2q\\
&amp;= -0.5\,log_20.5 -0.5\,log_20.5\\
&amp;= 1\\
\end{aligned}</p>
<p>To build a decision tree, we need to calculate two types of entropy using frequency tables as follows:   <br>
a) Entropy using the frequency table of one attribute:
\[
E(S) = - \sum_{i=1}^c\;p_i\,log_2(p_i)
\]
b) Entropy using the frequency table of two attributes:  <br>
\[
E(T,X) = - \sum_{c\in X}\;P(c)\,E(c)
\]</p>
<h2>Information Gain</h2>
<p>The information gain is based on the decrease in entropy after a dataset is split on an attribute. Constructing a decision tree is all about finding attribute that returns the highest information gain (i.e., the most homogeneous branches).    </p>
<p>Step 1: Calculate entropy of the target.    </p>
<p>Step 2: The dataset is then split on the different attributes. The entropy for each branch is calculated. Then it is added proportionally, to get total entropy for the split. The resulting entropy is subtracted from the entropy before the split. The result is the Information Gain, or decrease in entropy.    <br>
\begin{aligned}
Gain(T, X) &amp;= Entropy(T) - Entropy(T,X)\\
&amp;= E(T) - E(T,X)
\end{aligned}</p>
<p>Step 3: Choose attribute with the largest information gain as the decision node, divide the dataset by its branches and repeat the same process on every branch.     </p>
<p>Step 4a: A branch with entropy of 0 is a leaf node.     </p>
<p>Step 4b: A branch with entropy more than 0 needs further splitting.     </p>
<p>Step 5: The ID3 algorithm is run recursively on the non-leaf branches, until all data is classified.      </p>
<h2>Decision Tree Strengths and Weaknesses</h2>
<h3>Strengths</h3>
<ul>
<li>Easy to use,</li>
<li>Beautiful to draw/grow</li>
<li>Graphically describes the data</li>
<li>Bigger, custom classifiers can be built out of decision tree via ensemble methods.</li>
</ul>
<h3>Weaknesses</h3>
<ul>
<li>Prone to overfitting, esp too many features</li>
<li>
<h3>Needs to pay attention to tuning parameters, stop the growth of the tree (by tuning min samples split) at the appropriate time</h3>
</li>
</ul>
<h2>Other useful references:</h2>
<ul>
<li>[<a href="https://www.garysieling.com/blog/sklearn-gini-vs-entropy-criteria" title="Gini vs Entropy">Gini vs Entropy</a>]     </li>
<li>
<a href="http://www.saedsayad.com/decision_tree.htm" title="Decision Tree">Decision Tree</a> by Saed Sayad     </li>
<li>
<a href="http://scikit-learn.org/stable/modules/tree.html#tree" title="Scikit-Learn Decision Tree">Scikit-Learn Decision Tree</a>     </li>
<li>
<a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="Scikit-Learn Decision Tree Classifier">Scikit-Learn DT Classifier</a>     </li>
</ul>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="course-notes/machine-learning/02-supervised_learning-svm/" class="u-url">Supervised Learning - Support Vector Machine (SVM)</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-04-03T10:11:55+08:00" title="2017-04-03 10:11">2017-04-03 10:11</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Support Vector Machine (SVM)</h2>
<p>In <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine Learning">machine learning</a>, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical Classification">classification</a> and <a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression Analysis">regression analysis</a>. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-<a href="https://en.wikipedia.org/wiki/Probabilistic_classification" title="Probabilistic Classification">probabilistic</a> <a href="https://en.wikipedia.org/wiki/Binary_classification" title="Binary Classification">binary</a> <a href="https://en.wikipedia.org/wiki/Linear_classifier" title="Linear Classifier">linear classifier</a>. An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.</p>
<p>In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.</p>
<p>When data are not labeled, supervised learning is not possible, and an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning" title="Unsupervised Learning">unsupervised learnin</a>g approach is required, which attempts to find natural <a href="https://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster Analysis">clustering of the data</a> to groups, and then map new data to these formed groups. The clustering algorithm which provides an improvement to the support vector machines is called support vector clustering and is often[citation needed] used in industrial applications either when data are not labeled or when only some data are labeled as a preprocessing for a classification pass.</p>
<h3>Motivation</h3>
<p><a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical Classification">Classifying data</a> is a common task in <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine Learning">machine learning</a>. Suppose some given data points each belong to one of two classes, and the goal is to decide which class a new data point will be in. In the case of support vector machines, a data point is viewed as a \( p \)-dimensional vector (a list of \( p \) numbers), and we want to know whether we can separate such points with a \( (p-1) \)-dimensional <a href="https://en.wikipedia.org/wiki/Hyperplane_separation_theorem" title="Hyperplane Separation Theorem">hyperplane</a>. This is called a linear classifier. There are many hyperplanes that might classify the data. One reasonable choice as the best hyperplane is the one that represents the largest separation, or <a href="https://en.wikipedia.org/wiki/Margin_(machine_learning)" title="Margin (Machine Learning)">margin</a>, between the two classes. So we choose the hyperplane so that the distance from it to the nearest data point on each side is maximized. If such a hyperplane exists, it is known as the maximum-margin hyperplane and the linear classifier it defines is known as a maximum <a href="https://en.wikipedia.org/wiki/Margin_classifier" title="Margin Classifier">margin classifier</a>; or equivalently, the <a href="https://en.wikipedia.org/wiki/Perceptron" title="Perceptron">perceptron</a> of optimal stability.</p>
<h3>Definition</h3>
<p>More formally, a support vector machine constructs a <a href="https://en.wikipedia.org/wiki/Hyperplane_separation_theorem" title="Hyperplane Separation Theorem">hyperplane</a> or set of hyperplanes in a high- or infinite-dimensional space, which can be used for classification, regression, or other tasks. Intuitively, a good separation is achieved by the hyperplane that has the largest distance to the nearest training-data point of any class (so-called functional margin), since in general the larger the margin the lower the <a href="https://en.wikipedia.org/wiki/Generalization_error" title="Generalization Error">generalization error</a> of the classifier.</p>
<p>Whereas the original problem may be stated in a finite dimensional space, it often happens that the sets to discriminate are not <a href="https://en.wikipedia.org/wiki/Linear_separability" title="Linear Separability">linearly separable</a> in that space. For this reason, it was proposed that the original finite-dimensional space be mapped into a much higher-dimensional space, presumably making the separation easier in that space. To keep the computational load reasonable, the mappings used by SVM schemes are designed to ensure that dot products may be computed easily in terms of the variables in the original space, by defining them in terms of a <a href="https://en.wikipedia.org/wiki/Positive-definite_kernel" title="Kernel Function">kernel function</a> \( k(x,y) \) k(x,y) selected to suit the problem.</p>
<h3>Applications</h3>
<p>SVMs can be used to solve various real world problems:</p>
<ul>
<li>SVMs are helpful in <a href="https://en.wikipedia.org/wiki/Document_classification" title="Text/Document Classification">text and hypertext categorization</a> as their application can significantly reduce the need for labeled training instances in both the standard inductive and <a href="https://en.wikipedia.org/wiki/Transduction_(machine_learning)" title="Transduction (Machine Learning)">transductive</a> settings.</li>
<li>
<a href="https://en.wikipedia.org/wiki/Computer_vision#Recognition" title="Image Recognition">Classification of images</a> can also be performed using SVMs. Experimental results show that SVMs achieve significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback. This is also true of <a href="https://en.wikipedia.org/wiki/Image_segmentation" title="Image Segmentation">image segmentation</a> systems, including those using a modified version SVM that uses the privileged approach as suggested by Vapnik.</li>
<li>
<a href="https://en.wikipedia.org/wiki/Handwriting_recognition" title="Handwriting Recognition">Hand-written characters can be recognized</a> using SVM.</li>
<li>The SVM algorithm has been widely applied in the biological and other sciences. They have been used to classify proteins with up to 90% of the compounds classified correctly. <a href="https://en.wikipedia.org/wiki/Resampling_(statistics)#Permutation_tests" title="Permutation Tests">Permutation tests</a> based on SVM weights have been suggested as a mechanism for interpretation of SVM models.  Support vector machine weights have also been used to interpret SVM models in the past.  Posthoc interpretation of support vector machine models in order to identify features used by the model to make predictions is a relatively new area of research with special significance in the biological sciences.</li>
</ul>
<h3>History</h3>
<p>The original SVM algorithm was invented by Vladimir N. Vapnik and Alexey Ya. Chervonenkis in 1963. In 1992, Bernhard E. Boser, Isabelle M. Guyon and Vladimir N. Vapnik suggested a way to create nonlinear classifiers by applying the <a href="https://en.wikipedia.org/wiki/Kernel_method" title="Kernel Trick">kernel trick</a> to maximum-margin hyperplanes.  The current standard incarnation (soft margin) was proposed by Corinna Cortes and Vapnik in 1993 and published in 1995.    </p>
<h2>Other Useful Resources</h2>
<ul>
<li>
<a href="http://scikit-learn.org/stable/modules/svm.html" title="Scikit-Learn SVM">Scikit-Learn Support Vector Machine</a>     </li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="Scikit-Learn Support Vector Classifier">Scikit-Learn Support Vector Classifier</a></li>
<li><a href="http://scikit-learn.org/stable/modules/svm.html#svm-classification" title="SVC User Guide">Scikit-Learn SVC User Guide</a></li>
<li><a href="http://scikit-learn.org/stable/modules/svm.html#svm-kernels" title="SVM Kernels">Scikit-Learn Kernel Functions</a></li>
</ul>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="course-notes/machine-learning/01-supervised_learning-naive_bayes/" class="u-url">Supervised Learning - Naive Bayes</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-03-28T11:34:18+08:00" title="2017-03-28 11:34">2017-03-28 11:34</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Naive Bayes Classifier / Algorithm</h2>
<p>In <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine Learning">machine learning</a>, naive Bayes classifiers are a family of simple <a href="https://en.wikipedia.org/wiki/Probabilistic_classification" title="Probabilistic Classifier">probabilistic classifier</a>s based on applying <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" title="Bayes' Theorem">Bayes' theorem</a> with strong (naive) <a href="https://en.wikipedia.org/wiki/Independence_(probability_theory)" title="Independence Probability Theory">independence</a> assumptions between the features.</p>
<p>Naive Bayes has been studied extensively since the 1950s. It was introduced under a different name into the text retrieval community in the early 1960s, and remains a popular (baseline) method for text categorization, the problem of judging documents as belonging to one category or the other (such as spam or legitimate, sports or politics, etc.) with word frequencies as the features. With appropriate pre-processing, it is competitive in this domain with more advanced methods including support vector machines. It also finds application in automatic medical diagnosis.</p>
<p>Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" title="Maximum Likelihood Training">Maximum-likelihood training</a> can be done by evaluating a closed-form expression,[1]:718 which takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers.</p>
<p>In the statistics and computer science literature, Naive Bayes models are known under a variety of names, including simple Bayes and independence Bayes.  All these names reference the use of Bayes' theorem in the classifier's decision rule, but naive Bayes is not (necessarily) a Bayesian method.</p>
<p>Despite their naive design and apparently oversimplified assumptions, naive Bayes classifiers have worked quite well in many complex real-world situations. In 2004, an analysis of the Bayesian classification problem showed that there are sound theoretical reasons for the apparently implausible efficacy of naive Bayes classifiers.  Still, a comprehensive comparison with other classification algorithms in 2006 showed that Bayes classification is outperformed by other approaches, such as <a href="https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting" title="Boosted Trees">boosted trees</a> or <a href="https://en.wikipedia.org/wiki/Random_forest" title="Random Forests">random forests</a>.  </p>
<p>An advantage of naive Bayes is that it only requires a small number of training data to estimate the parameters necessary for classification.  </p>
<h3>Bayes Rules:</h3>
<p>Prior Probability * Test Evidence (in Probability) = Posterior Probability</p>
<p><strong>Cancer Example:</strong>       <br>
Prior Probabilities {Prior Cancer Probability is 1%}: <br>
\begin{aligned}
P(C) &amp;= 0.01\\
\therefore\; P(NC) &amp;= 1 - P(C)\\
&amp;= 0.99
\end{aligned}</p>
<p>Test Evidence, Sensitivity and Specificity Probabilities:    <br><em>Test Sensitivity</em>
\begin{aligned}
P(Pos|C) &amp;= 0.9\\
\therefore\; P(Neg|C) &amp;= 1 - 0.9\\
&amp;= 0.1 <br>
\end{aligned}</p>
<p><em>Test specificity</em>
\begin{aligned}
P(Neg|NC) &amp;= 0.9\\<br>
\therefore\; P(Pos|NC) &amp;= 1 - 0.9\\
&amp;= 0.1<br>
\end{aligned}</p>
<p>Joint Probability:   <br>
\begin{aligned}
P(C, Pos) &amp;= P(C) * P(Pos|C)\\
&amp;= 0.009\\\\
P(NC, Pos) &amp;= P(NC) * P(Pos|NC)\\
&amp;= 0.099\\\\
P(Pos) &amp;= P(C|Pos) + P(NC|Pos)\\
&amp;= 0.009 + 0.099 \\
&amp;= 0.108
\end{aligned}</p>
<p>Normalized Posterior Probability:
\begin{aligned}
P(C|Pos) &amp;= P(C, Pos) / P(Pos)\\
&amp;=  0.009 / 0.108\\
&amp;= 0.0833
\\\\
P(NC|Pos) &amp;= P(NC, Pos) / P(Pos)\\
&amp;=  0.099 / 0.108\\
&amp;= 0.9167
\end{aligned}</p>
<p>Legends:   <br>
- \(P(C)\): Prior Cancer Probability, in this case 1%
- \(P(NC)\): Prior non-Cancer Probability, 1-P(C), in this case 99%  <br>
- \(P(C, Pos)\): Joint probability that one having cancer AND tested positive   <br>
- \(P(NC, Pos)\): Joint probability that one does not have cancer AND tested positive    <br>
- \(P(C|Pos)\): Posterior probability of having cancer given one is tested positive   <br>
- \(P(NC|Pos)\): Posterior probability of NOT having cancer given one is tested positive   <br>
- \(P(Pos|C)\): Test sensitivity, Probability of tested positive if one has cancer   <br>
- \(P(Neg|NC)\): Test specificity, Probability of tested negative if one has NO cancer.</p>
<h3>Common Usage</h3>
<p>Naive Bayes is a pretty good algorithm for text learning.  Naive Bayes is called "Naive" because it works with <em>words</em> at various <em>length</em>, but ignores <em>word order</em>.    </p>
<h3>Pros:</h3>
<ul>
<li>Easy to implement      </li>
<li>Simple and efficient to run      </li>
<li>Big / Great feature spaces      </li>
</ul>
<h3>Cons:</h3>
<ul>
<li>It could break when phrases that encompasses multiple words that have distinctive meanings don't really work well.  For example Chicago Bulls will be interpreted as "Chicago" and "Bulls", but that's not what Chicago Bulls is.</li>
</ul>
<h2>Other references:</h2>
<ul>
<li><a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes" title="Scikit-Learn Naive Bayes">Scikit-Learn Naive Bayes</a></li>
<li>
<a href="http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html" title="Scikit-Learn Gaussian Naive Bayes">Scikit-Learn Gaussian Naive Bayes</a>    </li>
</ul>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="course-notes/machine-learning/00-supervised_learning-introduction/" class="u-url">Supervised Learning - Introduction</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-03-26T14:25:23+08:00" title="2017-03-26 14:25">2017-03-26 14:25</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Supervised Learning and Classifications</h2>
<p><strong>Supervised learning</strong> is the machine learning task of inferring a function from labeled <em>training data</em>. The training data consist of a set of training examples. In supervised learning, each example is a <em>pair</em> consisting of an input object (typically a vector) and a desired output value (also called the <em>supervisory signal</em>). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see <a href="https://en.wikipedia.org/wiki/Inductive_bias" title="Inductive Bias">inductive bias</a>).</p>
<p>The parallel task in human and animal psychology is often referred to as <a href="https://en.wikipedia.org/wiki/Concept_learning" title="Concept Learning">concept learning</a>.</p>
<h3>Overview</h3>
<p>In order to solve a given problem of supervised learning, one has to perform the following steps:</p>
<ol>
<li>Determine the type of training examples. Before doing anything else, the user should decide what kind of data is to be used as a training set. In the case of handwriting analysis, for example, this might be a single handwritten character, an entire handwritten word, or an entire line of handwriting.      </li>
<li>Gather a training set. The training set needs to be representative of the real-world use of the function. Thus, a set of input objects is gathered and corresponding outputs are also gathered, either from human experts or from measurements.      </li>
<li>Determine the input feature representation of the learned function. The accuracy of the learned function depends strongly on how the input object is represented. Typically, the input object is transformed into a feature vector, which contains a number of features that are descriptive of the object. The number of features should not be too large, because of the <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" title="Curse of Dimensionality">curse of dimensionality</a>; but should contain enough information to accurately predict the output.       </li>
<li>Determine the structure of the learned function and corresponding learning algorithm. For example, the engineer may choose to use <a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support Vector Machine (SVM)">support vector machines</a> or <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision Tree">decision trees</a>.         </li>
<li>Complete the design. Run the learning algorithm on the gathered training set. Some supervised learning algorithms require the user to determine certain control parameters. These parameters may be adjusted by optimizing performance on a subset (called a validation set) of the training set, or via <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" title="Cross Validation">cross-validation</a>.          </li>
<li>Evaluate the accuracy of the learned function. After parameter adjustment and learning, the performance of the resulting function should be measured on a test set that is separate from the training set.          </li>
<li>A wide range of supervised learning algorithms are available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the <a href="https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization" title="No Free Lunch Theorem">No free lunch theorem</a>).     </li>
</ol>
<p>There are four major issues to consider in supervised learning:</p>
<h4>Bias-variance tradeoff</h4>
<p><em>Main article: <a href="https://en.wikipedia.org/wiki/Bias-variance_dilemma" title="Bias Variance Dilemma">Bias-variance dilemma</a></em>     </p>
<p>A first issue is the tradeoff between bias and variance. Imagine that we have available several different, but equally good, training data sets. A learning algorithm is biased for a particular input \( x \) if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for \( x \) . A learning algorithm has high variance for a particular input \( x \) if it predicts different output values when trained on different training sets. The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm. Generally, there is a tradeoff between bias and variance. A learning algorithm with low bias must be "flexible" so that it can fit the data well. But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance. A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance (either automatically or by providing a bias/variance parameter that the user can adjust).</p>
<h4>Function complexity and amount of training data</h4>
<p>The second issue is the amount of training data available relative to the complexity of the "true" function (classifier or regression function). If the true function is simple, then an "inflexible" learning algorithm with high bias and low variance will be able to learn it from a small amount of data. But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be learnable from a very large amount of training data and using a "flexible" learning algorithm with low bias and high variance.</p>
<h4>Dimensionality of the input space</h4>
<p>A third issue is the dimensionality of the input space. If the input feature vectors have very high dimension, the learning problem can be difficult even if the true function only depends on a small number of those features. This is because the many "extra" dimensions can confuse the learning algorithm and cause it to have high variance. Hence, high input dimensionality typically requires tuning the classifier to have low variance and high bias. In practice, if the engineer can manually remove irrelevant features from the input data, this is likely to improve the accuracy of the learned function. In addition, there are many algorithms for feature selection that seek to identify the relevant features and discard the irrelevant ones. This is an instance of the more general strategy of dimensionality reduction, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.</p>
<h4>Noise in the output values</h4>
<p>A fourth issue is the degree of noise in the desired output values (the supervisory target variables). If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples. Attempting to fit the data too carefully leads to overfitting. You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation that part of the target function that cannot be modeled "corrupts" your training data - this phenomenon has been called deterministic noise. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.</p>
<p>In practice, there are several approaches to alleviate noise in the output values such as early stopping to prevent overfitting as well as detecting and removing the noisy training examples prior to training the supervised learning algorithm. There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased generalization error with statistical significance.   </p>
<h4>Other factors to consider (important)</h4>
<p>Other factors to consider when choosing and applying a learning algorithm include the following:</p>
<ol>
<li>Heterogeneity of the data. If the feature vectors include features of many different kinds (discrete, discrete ordered, counts, continuous values), some algorithms are easier to apply than others. Many algorithms, including Support Vector Machines, linear regression, logistic regression, neural networks, and nearest neighbor methods, require that the input features be numerical and scaled to similar ranges (e.g., to the [-1,1] interval). Methods that employ a distance function, such as nearest neighbor methods and support vector machines with Gaussian kernels, are particularly sensitive to this. An advantage of decision trees is that they easily handle heterogeneous data.       </li>
<li>Redundancy in the data. If the input features contain redundant information (e.g., highly correlated features), some learning algorithms (e.g., linear regression, logistic regression, and distance based methods) will perform poorly because of numerical instabilities. These problems can often be solved by imposing some form of regularization.       </li>
<li>Presence of interactions and non-linearities. If each of the features makes an independent contribution to the output, then algorithms based on linear functions (e.g., linear regression, logistic regression, Support Vector Machines, naive Bayes) and distance functions (e.g., nearest neighbor methods, support vector machines with Gaussian kernels) generally perform well. However, if there are complex interactions among features, then algorithms such as decision trees and neural networks work better, because they are specifically designed to discover these interactions. Linear methods can also be applied, but the engineer must manually specify the interactions when using them.     </li>
<li>When considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see cross validation). Tuning the performance of a learning algorithm can be very time-consuming. Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.       </li>
</ol>
<p>The most widely used learning algorithms are <a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support Vector Machine (SVM)">Support Vector Machines</a>, <a href="https://en.wikipedia.org/wiki/Linear_regression" title="Linear Regression">linear regression</a>, <a href="https://en.wikipedia.org/wiki/Logistic_regression" title="Logistic Regression">logistic regression</a>, <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" title="Naive Bayes">naive Bayes</a>, <a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis" title="Linear Discriminant Analysis">linear discriminant analysis</a>, <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision Tree">decision trees</a>, <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" title="K-Nearest Neighbors Algorithm">k-nearest neighbor algorithm</a>, and <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" title="Artificial Neural Network">Neural Networks</a> (<a href="https://en.wikipedia.org/wiki/Multilayer_perceptron" title="Multilayer Perceptron">Multilayer perceptron</a>).</p>
<p>In Machine learning, it is very important to train and test two different sets of data.  If we don't do that we could overfit the data.  We could think we know better what is actually going on than we actually know.</p>
<p>Usually when we get a dataset, we use 90% of the data as training data, and save 10% as testing data. When we do reporting, we use the results from the test data, as it more closely resemble real life application / tests on the algorithm.</p>
<h3>Overfitting and Underfitting</h3>
<p>In statistics and machine learning, one of the most common tasks is to fit a "model" to a set of training data, so as to be able to make reliable predictions on general untrained data.</p>
<p>In <strong>overfitting</strong>, a statistical model describes random error or noise instead of the underlying relationship. Overfitting occurs when a model is excessively complex, such as having too many parameters relative to the number of observations. A model that has been overfit has poor predictive performance, as it overreacts to minor fluctuations in the training data.</p>
<p><strong>Underfitting</strong> occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. Underfitting would occur, for example, when fitting a linear model to non-linear data. Such a model would have poor predictive performance.</p>
<p>The possibility of overfitting exists because the criterion used for training the model is not the same as the criterion used to judge the efficacy of a model. In particular, a model is typically trained by maximizing its performance on some set of training data. However, its efficacy is determined not by its performance on the training data but by its ability to perform well on unseen data. Overfitting occurs when a model begins to "memorize" training data rather than "learning" to generalize from trend. As an extreme example, if the number of parameters is the same as or greater than the number of observations, a simple model or learning process can perfectly predict the training data simply by memorizing the training data in its entirety, but such a model will typically fail drastically when making predictions about new or unseen data, since the simple model has not learned to generalize at all.</p>
<p>The potential for overfitting depends not only on the number of parameters and data but also the conformability of the model structure with the data shape, and the magnitude of model error compared to the expected level of noise or error in the data.</p>
<p>Even when the fitted model does not have an excessive number of parameters, it is to be expected that the fitted relationship will appear to perform less well on a new data set than on the data set used for fitting. In particular, the value of the coefficient of determination will shrink relative to the original training data.</p>
<p>In order to avoid overfitting, it is necessary to use additional techniques (e.g. <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" title="Cross Validation">cross-validation</a>, <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)" title="Regularization">regularization</a>, <a href="https://en.wikipedia.org/wiki/Early_stopping" title="Early Stopping">early stopping</a>, <a href="https://en.wikipedia.org/wiki/Pruning_(algorithm)" title="Pruning">pruning</a>, <a href="https://en.wikipedia.org/wiki/Prior_distribution" title="Bayesian Prior">Bayesian priors</a> on parameters or <a href="https://en.wikipedia.org/wiki/Bayesian_model_comparison" title="Bayesian Model Comparision">model comparison</a>), that can indicate when further training is not resulting in better generalization. The basis of some techniques is either (1) to explicitly penalize overly complex models, or (2) to test the model's ability to generalize by evaluating its performance on a set of data not used for training, which is assumed to approximate the typical unseen data that a model will encounter.</p>
<p>A good analogy for the overfitting problem is imagine a baby trying to learn what is a window or what is not a window, we start to show him windows and he detects at an initial phase that all windows have glasses, and a frame and you can look outside, some of them may be opened. If we keep showing the same windows the baby may also falsely deduce that all windows are green, and that all green frames are windows. Thus overfitting the problem.</p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="posts/multiple-github-accounts/" class="u-url">Setting Up Multiple GitHub User Account on One Machine</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-15T12:39:45+08:00" title="2016-11-15 12:39">2016-11-15 12:39</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>It is not unusual that developers need multiple github accounts on a single machine.  I was looking through the resources on the internet and found <a href="https://gist.github.com/jexchan/2351996/">this</a> the most useful.  None the less, I decided to write a post about this, just so for my own references.  </p>
<p>Here are the steps:
- Create the users (however many you need) on <a href="https://github.com/">github</a> first.     </p>
<ul>
<li>Use <code>ssh-keygen</code> to generate various ssh keys.  When prompted, make sure the keys are named appropriately so they can be identified easily.     </li>
</ul>
<pre class="code literal-block"><span></span>ssh-keygen -t rsa -C "{email1@youremail1.com}"
ssh-keygen -t rsa -C "{email1@youremail1.com}"
</pre>


<p>Make sure emails used are the ones you used for creating the github accounts.    </p>
<p>Usually ssh keys are stored under <code>home/{username}/.ssh</code> folder (or <code>/Users/{username}/.ssh</code> if you are on mac).  For example, the following keys are generated:    </p>
<pre class="code literal-block"><span></span>~/.ssh/id_rsa_{git_username1}
~/.ssh/id_rsa_{git_username2}
</pre>


<ul>
<li>Add the keys to SSH to the SSH Agent on the system:     </li>
</ul>
<pre class="code literal-block"><span></span>ssh-add ~/.ssh/id_rsa_{git_username1}
ssh-add ~/.ssh/id_rsa_{git_username2}
</pre>


<p>To delete ALL previously added keys:    </p>
<pre class="code literal-block"><span></span>ssh-add -D
</pre>


<p>To delete a previously added key:    </p>
<pre class="code literal-block"><span></span>ssh-add -d {id_rsa_keyname}
</pre>


<p>To list ALL previously added keys:    </p>
<pre class="code literal-block"><span></span>ssh-add -l
</pre>


<ul>
<li>The public keys need to be added to the github accounts accordingly.  </li>
</ul>
<pre class="code literal-block"><span></span>pbcopy &lt; ~/.ssh/id_rsa_{git_username1}.pub
</pre>


<p>Paste the content to corresponding <a href="https://github.com/settings/keys">github SSH key management</a>.   <br>
Repeat for all other keys for other accounts.     </p>
<ul>
<li>Configure SSH config</li>
</ul>
<pre class="code literal-block"><span></span>cd ~/.ssh/
nano config
</pre>


<ul>
<li>Add the following lines, modify accordingly:</li>
</ul>
<pre class="code literal-block"><span></span># github_{user1} account
Host github.com-{user1}
    HostName github.com
    User git
    IdentityFile ~/.ssh/id_rsa_{git_username1}
    IdentitiesOnly yes

# github_{user2} account
Host github.com-{user2}
    HostName github.com
    User git
    IdentityFile ~/.ssh/id_rsa_{git_username2}
    IdentitiesOnly yes
</pre>


<ul>
<li>Manage Global Git Configs.  You may either define those in command line or store them in a .gitconfig_global under     </li>
</ul>
<pre class="code literal-block"><span></span><span class="k">[core]</span>
       <span class="na">editor</span> <span class="o">=</span> <span class="s">atom -n -w</span>
<span class="s">       excludesfile = {filepath}/.gitignore_global</span>
<span class="k">[push]</span>
       <span class="na">default</span> <span class="o">=</span> <span class="s">upstream</span>
<span class="k">[merge]</span>
       <span class="na">conflictstyle</span> <span class="o">=</span> <span class="s">diff3</span>
<span class="k">[color]</span>
       <span class="na">ui</span> <span class="o">=</span> <span class="s">true</span>
<span class="k">[user]</span>
       <span class="na">name</span> <span class="o">=</span> <span class="s">{leave null, define this locally}</span>
<span class="s">       email = {leave null, define this locally}</span>
</pre>


<ul>
<li>Manage Local Git Configs  <br>
For example, github user1</li>
</ul>
<pre class="code literal-block"><span></span><span class="k">[user]</span>
        <span class="na">name</span> <span class="o">=</span> <span class="s">{github_username1}</span>
<span class="s">        email = {github_email1}</span>
<span class="k">[remote "origin"]</span>
        <span class="na">url</span> <span class="o">=</span> <span class="s">git@github.com-{user1}:{github_username}/{github_repo}</span>
</pre>


<p>Note that the host in URL has to be the right host defined earlier in the <code>~/.ssh/config</code> file.   </p>
<p>The same precaution has to be taken when cloning.  ie when executing <code>git clone</code> command, make sure the git host in 'copied and pasted' repo url is edited accordingly to the right user/host.  </p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="posts/matplotlib-on-osx-virtualenv/" class="u-url">Matplotlib on OSX with VirtualEnv/VirtualEnvWrapper (and Pip)</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-14T14:17:26+08:00" title="2016-11-14 14:17">2016-11-14 14:17</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>I like keeping my mini projects separate, mostly under its own virtual environment set up.  I use <a href="https://virtualenv.pypa.io/en/stable/">VirtualEnv</a> and <a href="https://virtualenvwrapper.readthedocs.io/en/latest/">VirtualEnvWrapper</a>.  </p>
<p>As I am working on code for data analysis and data visualization, inevitably I need the matplotlib library.  Reading various resources online, I managed to get it to work.  And with this post, I hope to document the steps for future reference.  </p>
<p>My environments:    <br>
- MacBookPro, OS macOS Sierra (10.12.1)   <br>
- VirtualEnv v.15.0.3   <br>
- python v.3.5.1  <br>
- Pip v.9.0.1    </p>
<p>Steps:  <br>
1. Activate the virtual environment: <code>workon {env}</code>  <br>
2. Show pip packages: <code>pip3 list</code>  <br>
3. Install necessary packages for data analysis and plotting: <code>pip install numpy scipy matplotlib pandas sympy nose</code>  <br>
4. Install PyQt5: <code>pip install PyQt5</code>   <br>
5. Modify matplotlibrc file: <code>nano {path to env}/lib/{pythonX.X}/site-packages/matplotlib/mpl-data/matplotlibrc</code>   <br>
      - At the  top of the configurations, define backend: <code>backend    :   Qt5Agg</code>  <br>
      - Then, define backend binding: <code>backend.qt5    :    PyQt5</code>  <br>
      - Save file.   </p>
<p>You are all set now.</p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="course-notes/descriptive-statistics/final_project/" class="u-url">Descriptive Statistics Final Project - Random Draws of Card Deck</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-14T11:39:38+08:00" title="2016-11-14 11:39">2016-11-14 11:39</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Instead of working on this project on a google sheet files, I decided to write my own python script to simulate the experiments.  </p>
<p>1) Histogram generated shown as below.   <br><img alt="Original Cards" src="images/descriptive-statistics/original52.png"><br>
Histogram for original card values are negatively skewed (towards right).    </p>
<p>2) Randomly Drawing 3 Cards   <br>
I wrote python scripts with pandas and matplotlib for the rest of the project.  </p>
<p>3) Distribution of Sum of 3 Randomly Drawn Cards   <br><strong>30 Samples of Sum of 3 Randomly Drawn Cards</strong>   <br><img alt="30 Samples of Sum of 3 Randomly Drawn Cards" src="images/descriptive-statistics/sample30.png"></p>
<p>Statistical Description of this sample with n = 30:  <br>
count  30.000000  <br>
mean   19.866667  <br>
std     5.550603  <br>
min     9.000000  <br>
25%    15.000000  <br>
50%    20.000000  <br>
75%    24.000000  <br>
max    30.000000    </p>
<p><strong>500 Samples of Sum of 3 Randomly Drawn Cards</strong>      <br><img alt="500 Samples of Sum of 3 Randomly Drawn Cards" src="images/descriptive-statistics/sample500.png"></p>
<p>Statistical Description of this sample with n = 500:  <br>
count  500.000000  <br>
mean    19.542000  <br>
std      5.337529  <br>
min      5.000000  <br>
25%     16.000000  <br>
50%     20.000000  <br>
75%     24.000000  <br>
max     30.000000    </p>
<p>4) As sample size increases, the curve gets more normalized (bell-shaped).     </p>
<p>5) Q:  Within what range will you expect approximately 90% of your draw values to fall? What is the approximate probability that you will get a draw value of at least 20? Make sure you justify how you obtained your values.    </p>
<p>To determine the range where 90% of the values fall, I found the closest corresponding z-value to be 1.28.   Therefore, with the following formula, I determined the range for our sample with 30 draws, and sample with 500 draws.   </p>
<p>\[<br>
  z = \frac{ x - \mu }{\sigma} \\
  x_{30, 90%} = 26.971442   \\
  x_{500, 90%} = 26.374   \\
\]  </p>
<p>To draw at least 20 from each of the samples, the corresponding z values are:    </p>
<p>\[
  z_{30, &gt;20} = \frac{20 - 19.866667}{5.550603} = 0.024021
  \\
  z_{500, &gt;20} = \frac{20 - 19.542000}{5.337529} = 0.085807 \\
\]</p>
<p>For sample with sample size 30, at z = 0.024021, the probability is 0.51 (51%).  That means the change of drawing 3 cards with sum greater than 20 from this sample is 49%.      </p>
<p>For sample with sample size 500, at z = 0.024021, the probability is 0.534 (53.4%).  That means the change of drawing 3 cards with sum greater than 20 from this sample is 46.6%.    </p>
<p>Finally, here's a <a href="http://www.stat.ufl.edu/~athienit/Tables/Ztable.pdf">link to the z-table</a> for reference.  </p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="course-notes/inferential-statistics/lesson-16/" class="u-url">Inferential Statistics - Chi-Squared Tests</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-09T13:10:55+08:00" title="2016-11-09 13:10">2016-11-09 13:10</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h3>Types of Data</h3>
<ul>
<li>
<strong>Ordinal Data</strong> - ranks with no fixed intervals nor zeros   </li>
<li>
<strong>Interval Data</strong> - ranks with equal intervals     </li>
<li>
<strong>Ratio Data</strong> - ranks with equal intervals and an absolute zero   </li>
<li>
<strong>Nominal/Categorical Data</strong> - data with no numerical values (typically yes/no, in/out, successful/unsuccessful)    </li>
</ul>
<h3>Types of Tests</h3>
<ul>
<li>
<strong>Parametric</strong> - hypothesis testing that make assumptions about the parameters of the populations, \( \mu \) and \( \sigma \).</li>
<li>
<strong>Non-Parametric</strong> - hypothesis testing that do not require population parameters</li>
</ul>
<h3>Characteristics of Non-Parametric Testings</h3>
<ul>
<li>There is no way to calculate a mean or standard deviation      </li>
<li>The data is based on frequencies or proportions    </li>
<li>The data is nominal (successful vs unsuccessful, 1 or 0, yes or no, mountain vs beach etc.)    </li>
<li>The data are not based on Normal distribution    </li>
</ul>
<h3>\( \chi^2 \) Goodness of Fit Test</h3>
<p>How well our observed frequencies 'fit' our expected frequencies? <br>
\[
  \chi ^2 = \sum{ \frac{(f_0 - f_e)^2}{f_e} }
\]
\( \chi^2 \) is smaller when the observed value is closer to the expected value.   <br>
\( \chi^2 \) is NEVER negative and therefore \( \chi^2 \) statistic is one-directional.     </p>
<p>For each category, we have one \( \chi^2 \) statistics.  When we have more categories, \( \chi^2 \) statistics get bigger with the number of categories.    </p>
<h3>Degrees of Freedom</h3>
<p>For n x m, 2 dimensional nominal data:
\[
  df = (N_n - 1) * (N_m - 1) \\
  \text{where } N_n \text{ and }N_m \text{ are number of columns, and number of rows respectively. }
\]</p>
<h3>Cramer's V \( (\phi_c) \)</h3>
<p>\[
  \phi_c = \sqrt{\frac{\chi^2}{n(k-1)}}  \\
  k \text{ is the smaller number between number of rows or number of columns}\\
  n \text{ is the total sample size regardless of treatments}
\]</p>
<h3>Assumptions and Restrictions for \(\chi^2\) Tests</h3>
<ul>
<li>Avoid dependent observations.  Independence will be violated if any participants were given two treatments instead of one.     </li>
<li>Avoid small expected frequencies, therefore in general have a larger number of participants.   Sample size should be at least 20, and each expected cell frequencies should be at least 5.    </li>
</ul>
</div>
    </div>
    </article>
</div>
        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-5.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-3.html" rel="next">Older posts</a>
            </li>
        </ul></nav><script>var disqus_shortname="chowygit";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>

    
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73098247-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
