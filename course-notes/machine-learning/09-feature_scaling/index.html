<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title> =^..^= MEH · Feature Scaling </title>
<link href="../../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/poole.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/hyde.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/code.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700%7CAbril+Fatface">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.xml">
<link rel="canonical" href="https://chowy1026.github.io/course-notes/machine-learning/09-feature_scaling/">
<link rel="icon" href="../../../images/favicon.png" sizes="64x64">
<link rel="icon" href="../../../images/icon_512x512.png" sizes="512x512">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: true
            },
            displayAlign: 'center', // Change this to 'left' to left equations.
            "HTML-CSS": {
                styles: {'.MathJax_Display': {"margin": 0}}
            }
        });
    </script><script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]--><meta name="author" content="cHoWy">
<link rel="prev" href="../08-unsupervised_learning-clustering/" title="Unsupervised Learning - Clustering" type="text/html">
<link rel="next" href="../10-text_learning/" title="Text Learning" type="text/html">
<meta property="og:site_name" content=" =^..^= MEH">
<meta property="og:title" content="Feature Scaling">
<meta property="og:url" content="https://chowy1026.github.io/course-notes/machine-learning/09-feature_scaling/">
<meta property="og:description" content="Introduction
Feature scaling is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally perform">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-04-20T06:53:53+08:00">
</head>
<body class="test">
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

    <div class="sidebar">
        <div class="container sidebar-sticky">
            <div class="sidebar-about">
              <h1>
                <a href="https://chowy1026.github.io/">
                      <h1 id="brand"><a href="https://chowy1026.github.io/" title=" =^..^= MEH" rel="home">

        <span id="blog-title"> =^..^= MEH</span>
    </a></h1>

                </a>
              </h1>
                <p class="lead"></p>

            </div>
                <nav id="menu" role="navigation" class="sidebar-nav"><a class="sidebar-nav-item" href="../../../posts/index.html">Articles</a>
        <a class="sidebar-nav-item" href="../../index.html">Course Notes</a>
        <a class="sidebar-nav-item" href="../../../links/index.html">Links</a>
        <a class="sidebar-nav-item" href="../../../books/index.html">Books</a>
        <a class="sidebar-nav-item" href="../../../archives/archives.html">Archives</a>
        <a class="sidebar-nav-item" href="../../../tags.html">Tags</a>
    
    
    </nav><footer id="footer"><p class="footer">
              <span class="icon_row">

                <a href="mailto:chowy1026@gmail.com">
                  <img class="social_icon" src="../../../images/envelope1.png" title="email" width="24"></a> ·
                <!--<a href="">
                  <img class="social_icon" src="/images/twitter-black-shape1.png" title="twitter" width="24" /></a> &middot;-->
                <a href="https://github.com/chowy1026/">
                  <img class="social_icon" src="../../../images/github-character1.png" title="github" width="24"></a>
              </span>
              <br><br><span class="copyright">
              
Contents © 2017 by <a href="mailto:chowy1026@gmail.com">cHoWy</a> ·
Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a> <br><a href="http://hyde.getpoole.com" target="_blank">Hyde</a> theme by <a href="https://twitter.com/mdo" target="_blank">@mdo</a>

            </span>
            </p>
            
        </footer>
</div>
    </div>

    <div class="content container" id="content">
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><h1 class="post-title p-name"><a href="." class="u-url">Feature Scaling</a></h1>

    <span class="post-date">
      <time class="published dt-published" datetime="2017-04-20T06:53:53+08:00" itemprop="datePublished" title="2017-04-20 06:53">2017-04-20 06:53</time></span>

    
    

    <div class="e-content entry-content" itemprop="articleBody text">
    <div>
<h3>Introduction</h3>
<p>Feature scaling is a method used to standardize the range of independent variables or features of data. In <a href="https://en.wikipedia.org/wiki/Data_processing" title="Data Processing">data processing</a>, it is also known as data normalization and is generally performed during the data preprocessing step.</p>
<p>Since the range of values of raw data varies widely, in some <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine Learning">machine learning</a> algorithms, objective functions will not work properly without <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)" title="Normalization">normalization</a>. For example, the majority of <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Classifiers">classifiers</a> calculate the distance between two points by the <a href="https://en.wikipedia.org/wiki/Euclidean_distance" title="Euclidean Distance">Euclidean distance</a>. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.</p>
<p>Another reason why feature scaling is applied is that <a href="https://en.wikipedia.org/wiki/Gradient_descent" title="Gradient Descent">gradient descent</a> converges much faster with feature scaling than without it.</p>
<h3>Methods</h3>
<h4>Rescaling</h4>
<p>The simplest method is rescaling the range of features to scale the range in [0, 1] or [−1, 1]. Selecting the target range depends on the nature of the data. The general formula is given as:</p>
<p>\( x' = \frac{x- \text{min}(x)} {{\text{max}}(x)-{\text{min}}(x)} \)</p>
<p>where \(  x \) is an original value, \( x' \) is the normalized value. For example, suppose that we have the students' weight data, and the students' weights span [160 pounds, 200 pounds]. To rescale this data, we first subtract 160 from each student's weight and divide the result by 40 (the difference between the maximum and minimum weights).</p>
<h4>Standardization</h4>
<p>In machine learning, we can handle various types of data, e.g. audio signals and pixel values for image data, and this data can include multiple <a href="https://en.wikipedia.org/wiki/Dimensions" title="Dimensions">dimensions</a>. Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance. This method is widely used for normalization in many machine learning algorithms (e.g., <a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support Vector Machine">support vector machines</a>, <a href="https://en.wikipedia.org/wiki/Logistic_regression" title="Logistic Regression">logistic regression</a>, and <a href="https://en.wikipedia.org/wiki/Neural_network" title="Neural Network">neural networks</a>). This is typically done by calculating <a href="https://en.wikipedia.org/wiki/Standard_score" title="Standard Score">standard scores</a>. The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values (mean is already subtracted) of each feature by its standard deviation.</p>
<p>\( x'= \frac{x-{\bar {x}}}{\sigma } \)</p>
<p>Where \(  x \) is the original feature vector, \( \bar {x} \) is the mean of that feature vector, and \( \sigma \)  is its standard deviation.</p>
<h4>Scaling to unit length</h4>
<p>Another option that is widely used in machine-learning is to scale the components of a feature vector such that the complete vector has length one. This usually means dividing each component by the <a href="https://en.wikipedia.org/wiki/Euclidean_length" title="Euclidean Length">Euclidean length</a> of the vector. In some applications (e.g. Histogram features) it can be more practical to use the L1 norm (i.e. Manhattan Distance, City-Block Length or <a href="https://en.wikipedia.org/wiki/Taxicab_Geometry" title="Taxicab Geometry">Taxicab Geometry</a>) of the feature vector:</p>
<p>\(  x'= \frac {x}{||x||} \)
This is especially important if in the following learning steps the Scalar Metric is used as a distance measure.</p>
</div>
    </div>
    <aside class="postpromonav"><nav><div class="pager hidden-print pagination">

            <span class="previous pagination-item older">
                <a href="../08-unsupervised_learning-clustering/" rel="prev" title="Unsupervised Learning - Clustering">
                Previous post
                </a>
            </span>


            <span class="next pagination-item newer">
                <a href="../10-text_learning/" rel="next" title="Text Learning">
Next post
              </a>
            </span>

        </div>

    </nav></aside><section class="comments hidden-print"><h2>Comments</h2>
                        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="chowygit",
            disqus_url="https://chowy1026.github.io/course-notes/machine-learning/09-feature_scaling/",
        disqus_title="Feature Scaling",
        disqus_identifier="cache/course-notes/machine-learning/09-feature_scaling.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="chowygit";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>

    
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73098247-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
