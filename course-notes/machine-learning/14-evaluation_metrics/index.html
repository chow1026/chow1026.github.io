<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title> =^..^= MEH · Evaluation Metrics </title>
<link href="../../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/poole.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/hyde.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/code.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700%7CAbril+Fatface">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.xml">
<link rel="canonical" href="https://chow1026.github.io/course-notes/machine-learning/14-evaluation_metrics/">
<link rel="icon" href="../../../images/favicon.png" sizes="64x64">
<link rel="icon" href="../../../images/icon_512x512.png" sizes="512x512">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: true
            },
            displayAlign: 'center', // Change this to 'left' to left equations.
            "HTML-CSS": {
                styles: {'.MathJax_Display': {"margin": 0}}
            }
        });
    </script><script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]--><meta name="author" content="cHoWy">
<link rel="prev" href="../13-validation/" title="Validation" type="text/html">
<link rel="next" href="../../data-visualization/01-visualization_fundamentals/" title="Visualization Fundamentals" type="text/html">
<meta property="og:site_name" content=" =^..^= MEH">
<meta property="og:title" content="Evaluation Metrics">
<meta property="og:url" content="https://chow1026.github.io/course-notes/machine-learning/14-evaluation_metrics/">
<meta property="og:description" content="The simplest metric is Accuracy.  It is defined as :
Accuracy = no. of items in a class labeled correctly / all items in that class
There are shortcomings of accuracy:      

not ideal for skewed clas">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-04-20T07:04:44+08:00">
</head>
<body class="test">
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

    <div class="sidebar">
        <div class="container sidebar-sticky">
            <div class="sidebar-about">
              <h1>
                <a href="https://chow1026.github.io/">
                      <h1 id="brand"><a href="https://chow1026.github.io/" title=" =^..^= MEH" rel="home">

        <span id="blog-title"> =^..^= MEH</span>
    </a></h1>

                </a>
              </h1>
                <p class="lead"></p>

            </div>
                <nav id="menu" role="navigation" class="sidebar-nav"><a class="sidebar-nav-item" href="../../../posts/index.html">Articles</a>
        <a class="sidebar-nav-item" href="../../index.html">Course Notes</a>
        <a class="sidebar-nav-item" href="../../../links/index.html">Links</a>
        <a class="sidebar-nav-item" href="../../../books/index.html">Books</a>
        <a class="sidebar-nav-item" href="../../../archives/archives.html">Archives</a>
        <a class="sidebar-nav-item" href="../../../tags.html">Tags</a>
    
    
    </nav><footer id="footer"><p class="footer">
              <span class="icon_row">

                <a href="mailto:chowy1026@gmail.com">
                  <img class="social_icon" src="../../../images/envelope1.png" title="email" width="24"></a> ·
                <!--<a href="">
                  <img class="social_icon" src="/images/twitter-black-shape1.png" title="twitter" width="24" /></a> &middot;-->
                <a href="https://github.com/chowy1026/">
                  <img class="social_icon" src="../../../images/github-character1.png" title="github" width="24"></a>
              </span>
              <br><br><span class="copyright">
              
Contents © 2017 by <a href="mailto:chowy1026@gmail.com">cHoWy</a> ·
Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a> <br><a href="http://hyde.getpoole.com" target="_blank">Hyde</a> theme by <a href="https://twitter.com/mdo" target="_blank">@mdo</a>

            </span>
            </p>
            
        </footer>
</div>
    </div>

    <div class="content container" id="content">
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><h1 class="post-title p-name"><a href="." class="u-url">Evaluation Metrics</a></h1>

    <span class="post-date">
      <time class="published dt-published" datetime="2017-04-20T07:04:44+08:00" itemprop="datePublished" title="2017-04-20 07:04">2017-04-20 07:04</time></span>

    
    

    <div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>The simplest metric is Accuracy.  It is defined as :</p>
<p>Accuracy = no. of items in a class labeled correctly / all items in that class</p>
<p>There are shortcomings of accuracy:      </p>
<ul>
<li>not ideal for skewed classes    </li>
<li>may want to err on side of guessing innocent   </li>
<li>may want to err of side of guessing guilty   </li>
</ul>
<h3>Model Evaluation Metrics</h3>
<p>There are 3 different approaches to evaluate the quality of predictions of a model:    </p>
<ul>
<li>
<strong>Estimator score method</strong>: Estimators have a score method providing a default evaluation criterion for the problem they are designed to solve. This is not discussed on this page, but in each estimator’s documentation.     </li>
<li>
<strong>Scoring parameter</strong>: Model-evaluation tools using <a href="http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation" title="Cross Validation">cross-validation</a> (such as model_selection.cross_val_score and model_selection.GridSearchCV) rely on an internal scoring strategy. This is discussed in the section <a href="http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter" title="Scoring Parameter">The scoring parameter: defining model evaluation rules</a>.     </li>
<li>
<strong>Metric functions</strong>: The metrics module implements functions assessing prediction error for specific purposes. These metrics are detailed in sections on <a href="http://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics" title="Classification Metrics">Classification metrics</a>, <a href="http://scikit-learn.org/stable/modules/model_evaluation.html#multilabel-ranking-metrics" title="Multilabel Ranking Metrics">Multilabel ranking metrics</a>, <a href="http://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics" title="Regression Metrics">Regression metrics</a> and <a href="http://scikit-learn.org/stable/modules/model_evaluation.html#clustering-metrics" title="Clustering Metrics">Clustering metrics</a>.     </li>
</ul>
<p>Finally, Dummy estimators are useful to get a baseline value of those metrics for random predictions.</p>
<p>For the most common use cases, you can designate a scorer object with the scoring parameter; the table below shows all possible values. All scorer objects follow the convention that <strong>higher return values are better than lower return values</strong>.</p>
<p><strong>Classification</strong>:       </p>
<ul>
<li>confusion matrix</li>
<li>accuracy   </li>
<li>average precision     </li>
<li>precision score    </li>
<li>recall score    </li>
<li>f1 score (micro, macro, weighted, samples)    </li>
<li>roc auc (area under curve)      </li>
<li>log loss</li>
</ul>
<p><strong>Clustering</strong>:       </p>
<ul>
<li>adjusted rand score</li>
</ul>
<p><strong>Regression</strong>:      </p>
<ul>
<li>Mean absolute error</li>
<li>Mean square error</li>
<li>Median absolute error</li>
<li>\(r^2\) score</li>
</ul>
<h3>Confusion Matrix</h3>
<p>In the field of <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine Learning">machine learning</a> and specifically the problem of <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical Classification">statistical classification</a>, a <strong>confusion matrix</strong>, also known as an error matrix,[4] is a specific table layout that allows visualization of the performance of an algorithm, typically a <a href="https://en.wikipedia.org/wiki/Supervised_learning" title="Supervised Learning">supervised learning</a> one (in <a href="https://en.wikipedia.org/wiki/Unsupervised_learning" title="Unsupervised Learning">unsupervised learning</a> it is usually called a <strong>matching matrix</strong>). Each column of the matrix represents the instances in a predicted class while each row represents the instances in an actual class (or vice versa).   The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabelling one as another).</p>
<p>It is a special kind of <a href="https://en.wikipedia.org/wiki/Contingency_table" title="Contingency Table">contingency table</a>, with two dimensions ("actual" and "predicted"), and identical sets of "classes" in both dimensions (each combination of dimension and class is a variable in the contingency table).</p>
<h4>NOTES FROM UDACITY CLASS:</h4>
<p><strong>Recall</strong>: True Positive / (True Positive + False Negative). Out of all the items that are truly positive, how many were correctly classified as positive. Or simply, how many positive items were 'recalled' from the dataset.      </p>
<p><strong>Precision</strong>: True Positive / (True Positive + False Positive). Out of all the items labeled as positive, how many truly belong to the positive class.      </p>
<h4>Terminology and derivations from a confusion matrix</h4>
<p><strong>condition positive (P)</strong> :: the number of real positive cases in the data      </p>
<p><strong>condition negatives (N)</strong> :: the number of real negative cases in the data</p>
<p><strong>true positive (TP)</strong> :: eqv. with hit    </p>
<p><strong>true negative (TN)</strong> :: eqv. with correct rejection    </p>
<p><strong>false positive (FP)</strong> :: eqv. with <a href="https://en.wikipedia.org/wiki/False_alarm" title="False Alarm">false alarm</a>, <a href="https://en.wikipedia.org/wiki/Type_I_error" title="Type I Error">Type I error</a></p>
<p><strong>false negative (FN)</strong> :: eqv. with miss, <a href="https://en.wikipedia.org/wiki/Type_II_error" title="Type II Error">Type II error</a></p>
<hr>
<p><a href="https://en.wikipedia.org/wiki/Sensitivity_(test)" title="Sensitivity">sensitivity</a>, <a href="https://en.wikipedia.org/wiki/Information_retrieval#Recall" title="Recall">recall</a>, <a href="https://en.wikipedia.org/wiki/Hit_rate" title="Hit Rate">hit rate</a>, or <a href="https://en.wikipedia.org/wiki/Sensitivity_(test)" title="True Positive Rate (TPR)">true positive rate (TPR)</a> ::
\[
  \mathrm{TPR} = \frac{\mathrm{TP}}{P} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}
\]</p>
<p><a href="https://en.wikipedia.org/wiki/Specificity_(tests)" title="Speciticity">specificity</a> or <a href="https://en.wikipedia.org/wiki/Specificity_(tests)" title="True Negative Rate (TNR)">true negative rate (TNR)</a> ::
\[
  \mathrm{TNR} = \frac{\mathrm{TN}}{N} = \frac{\mathrm{TN}}{\mathrm{TN} + \mathrm{FP}}
\]</p>
<p><a href="https://en.wikipedia.org/wiki/Information_retrieval#Precision" title="Precision">precision</a> or <a href="https://en.wikipedia.org/wiki/Positive_predictive_value" title="Positive Predictive Value">positive predictive value (PPV)</a> :: <br>
\[
  \mathrm{PPV} = \frac{\mathrm{TP}}{\mathrm {TP} +\mathrm {FP}}
\]</p>
<p><a href="https://en.wikipedia.org/wiki/Negative_predictive_value" title="Negative Predictive Value">negative predictive value (NPV)</a> ::  <br>
\[
  \mathrm{NPV} = \frac{\mathrm{TN}}{\mathrm {TN} +\mathrm {FN}}
\]</p>
<p><strong>miss rate</strong> or <a href="https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#False_positive_and_false_negative_rates" title="False Negative Rate">false negative rate (FNR)</a> :: <br>
\[
  \mathrm{FNR} = \frac{\mathrm{FN}}{P} = \frac{\mathrm{FN}}{\mathrm{FN} + \mathrm{TP}} = 1 - \mathrm{TPR}
\]</p>
<p><a href="https://en.wikipedia.org/wiki/Information_retrieval#Fall-out" title="Fall Out">fall-out</a> or <a href="https://en.wikipedia.org/wiki/Information_retrieval#Fall-out" title="False Positive Rate">false positive rate (FPR)</a> ::  <br>
\[
  \mathrm{FPR} = \frac{\mathrm{FP}}{N} = \frac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}} = 1 - \mathrm{TNP}
\]</p>
<p><a href="https://en.wikipedia.org/wiki/False_discovery_rate" title="False Discovery Rate">false discovery rate (FDR)</a> ::   <br>
\[
  \mathrm{FDR} = \frac{\mathrm{FP}}{\mathrm {FP} +\mathrm {TP}} = 1 - \mathrm{PPV}
\]</p>
<p><a href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values" title="False Omission Rate">false omission rate (FOR)</a>  ::    <br>
\[
  \mathrm{FOR} = \frac{\mathrm{FN}}{\mathrm {FN} +\mathrm {TN}} = 1 - \mathrm{NPV}
\]</p>
<hr>
<p><a href="https://en.wikipedia.org/wiki/Accuracy" title="Accuracy">accuracy (ACC)</a> ::  <br>
\[
  \mathrm{ACC} = \frac{\mathrm{TP} + \mathrm{TN}}{ {P} + {N}}
\]</p>
<p><a href="https://en.wikipedia.org/wiki/F1_score" title="F1 Score">F1 score</a> :: is the <a href="https://en.wikipedia.org/wiki/Harmonic_mean#Harmonic_mean_of_two_numbers" title="Harmonic Mean">harmonic mea</a>n of <a href="https://en.wikipedia.org/wiki/Information_retrieval#Precision" title="Precision">precision</a> and <a href="https://en.wikipedia.org/wiki/Sensitivity_(test)" title="Sensitivity">sensitivity</a>     <br>
\[
  F_{1} = 2 \cdot \frac{\mathrm{PPV} \cdot \mathrm{TPR}}{\mathrm{PPV} + \mathrm{TPR}} =  \frac{2\mathrm{TP}}{2\mathrm{TP} + \mathrm{FP} + \mathrm{FN}}
\]</p>
<p><a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient" title="Matthews Correlation Coefficient">Matthews correlation coefficient (MCC)</a> ::   <br>
\[
  \mathrm{MCC} = \frac{ \mathrm{TP} \times \mathrm{TN} - \mathrm{FP} \times \mathrm{FN} }{ \sqrt{(\mathrm{TP} + \mathrm{FP} )(\mathrm{TP} + \mathrm{FN} )( \mathrm{TN} + \mathrm{FP} )( \mathrm{TN} + \mathrm{FN} )} }
\]</p>
<p><a href="https://en.wikipedia.org/wiki/Informedness" title="Informedness">Informedness</a> or <strong>Bookmaker Informedness (BM)</strong> ::   <br>
\[
  \mathrm{BM}  = \mathrm{TPR} + \mathrm{TNR} -1
\]</p>
<p><strong>Markedness (MK)</strong> ::    <br>
\[
  \mathrm{MK}  = \mathrm{PPV} + \mathrm{NPV} -1
\]</p>
<hr>
<table class="wikitable" align="center" style="text-align:center; border:none; background:transparent;"><tbody>
<tr>
<td colspan="2" style="border:none;"></td>
<td colspan="2" style="background:#eeeebb;"><b>predicted condition</b></td>
</tr>
<tr>
<td style="border:none;"></td>
<td style="background:#dddddd;"><a href="https://en.wikipedia.org/wiki/Statistical_population" title="Statistical population">total population</a></td>
<td style="background:#ffffcc;">prediction positive</td>
<td style="background:#ddddaa;">prediction negative</td>
<td style="background:#eeeecc;">
<a href="https://en.wikipedia.org/wiki/Prevalence" title="Prevalence">Prevalence</a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ condition positive</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ total population</span></span></span></span>
</td>
</tr>
<tr>
<td rowspan="2" style="background:#bbeeee;"><b>true<br>
condition</b></td>
<td style="background:#ccffff;">condition<br>
positive</td>
<td style="background:#ccffcc;"><span style="color:#006600;"><b><a href="https://en.wikipedia.org/wiki/True_positive" class="mw-redirect" title="True positive">True Positive (TP)</a></b></span></td>
<td style="background:#eedddd;">
<span style="color:#cc0000;"><b><a href="https://en.wikipedia.org/wiki/False_Negative" class="mw-redirect" title="False Negative">False Negative (FN)</a></b></span><br>
(<a href="https://en.wikipedia.org/wiki/Type_II_error" class="mw-redirect" title="Type II error">type II error</a>)</td>
<td style="background:#eeffcc;">
<a href="https://en.wikipedia.org/wiki/True_Positive_Rate" class="mw-redirect" title="True Positive Rate">True Positive Rate (TPR)</a>, <a href="https://en.wikipedia.org/wiki/Sensitivity_(tests)" class="mw-redirect" title="Sensitivity (tests)">Sensitivity</a>, <a href="https://en.wikipedia.org/wiki/Recall_(information_retrieval)" class="mw-redirect" title="Recall (information retrieval)">Recall</a>, Probability of Detection <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ TP</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ condition positive</span></span></span></span>
</td>
<td style="background:#ffeecc;">
<a href="https://en.wikipedia.org/wiki/False_Negative_Rate" class="mw-redirect" title="False Negative Rate">False Negative Rate (FNR)</a>, Miss Rate <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ FN</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ condition positive</span></span></span></span>
</td>
</tr>
<tr>
<td style="background:#aadddd;">condition<br>
negative</td>
<td style="background:#ffdddd;">
<span style="color:#cc0000;"><b><a href="https://en.wikipedia.org/wiki/False_Positive" class="mw-redirect" title="False Positive">False Positive (FP)</a></b></span><br>
(<a href="https://en.wikipedia.org/wiki/Type_I_error" class="mw-redirect" title="Type I error">Type I error</a>)</td>
<td style="background:#bbeebb;"><span style="color:#006600;"><b><a href="https://en.wikipedia.org/wiki/True_negative" class="mw-redirect" title="True negative">True Negative (TN)</a></b></span></td>
<td style="background:#eeddbb;">
<a href="https://en.wikipedia.org/wiki/False_Positive_Rate" class="mw-redirect" title="False Positive Rate">False Positive Rate (FPR)</a>, <a href="https://en.wikipedia.org/wiki/Information_retrieval" title="Information retrieval"><span class="nowrap">Fall-out</span></a>, Probability of False Alarm <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ FP</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ condition negative</span></span></span></span>
</td>
<td style="background:#ddeebb;">
<a href="https://en.wikipedia.org/wiki/True_Negative_Rate" class="mw-redirect" title="True Negative Rate">True Negative Rate (TNR)</a>, <a href="https://en.wikipedia.org/wiki/Specificity_(tests)" class="mw-redirect" title="Specificity (tests)">Specificity</a> (SPC) <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ TN</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ condition negative</span></span></span></span>
</td>
</tr>
<tr>
<td style="border:none;"></td>
<td rowspan="2" style="background:#cceecc;border-top:solid grey;border-right:solid grey">
<a href="https://en.wikipedia.org/wiki/Accuracy_and_precision" title="Accuracy and precision">Accuracy</a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ TP + Σ TN</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ total population</span></span></span></span>
</td>
<td style="background:#ccffee;border-top:solid grey;">
<a href="https://en.wikipedia.org/wiki/Positive_Predictive_Value" class="mw-redirect" title="Positive Predictive Value">Positive Predictive Value (PPV)</a>, <a href="https://en.wikipedia.org/wiki/Precision_(information_retrieval)" class="mw-redirect" title="Precision (information retrieval)">Precision</a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ TP</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ prediction positive</span></span></span></span>
</td>
<td style="background:#eeddee;border-bottom:solid grey;">
<a href="https://en.wikipedia.org/wiki/False_omission_rate" class="mw-redirect" title="False omission rate">False Omission Rate (FOR)</a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ FN</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ prediction negative</span></span></span></span>
</td>
<td style="background:#eeeeee;">
<a href="https://en.wikipedia.org/wiki/Positive_likelihood_ratio" class="mw-redirect" title="Positive likelihood ratio">Positive Likelihood Ratio <span class="nowrap">(LR+)</span></a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">TPR</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">FPR</span></span></span></span>
</td>
<td rowspan="2" style="background:#dddddd;">
<a href="https://en.wikipedia.org/wiki/Diagnostic_odds_ratio" title="Diagnostic odds ratio">Diagnostic Odds Ratio (DOR)</a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">LR+</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">LR−</span></span></span></span>
</td>
</tr>
<tr>
<td style="border:none;"></td>
<td style="background:#cceeff;border-top:solid grey;">
<a href="https://en.wikipedia.org/wiki/False_Discovery_Rate" class="mw-redirect" title="False Discovery Rate">False Discovery Rate (FDR)</a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ FP</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ prediction positive</span></span></span></span>
</td>
<td style="background:#aaddcc;border-bottom:solid grey;">
<a href="https://en.wikipedia.org/wiki/Negative_Predictive_Value" class="mw-redirect" title="Negative Predictive Value">Negative Predictive Value (NPV)</a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">Σ TN</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">Σ prediction negative</span></span></span></span>
</td>
<td style="background:#cccccc;">
<a href="https://en.wikipedia.org/wiki/Negative_likelihood_ratio" class="mw-redirect" title="Negative likelihood ratio">Negative Likelihood Ratio <span class="nowrap">(LR−)</span></a> <span style="font-size:118%;white-space:nowrap;">= <span class="texhtml"><span class="sfrac nowrap" style="display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;"><span style="display:block; line-height:1em; margin:0 0.1em;">FNR</span><span style="display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;">TNR</span></span></span></span>
</td>
</tr>
</tbody></table>
</div>
    </div>
    <aside class="postpromonav"><nav><div class="pager hidden-print pagination">

            <span class="previous pagination-item older">
                <a href="../13-validation/" rel="prev" title="Validation">
                Previous post
                </a>
            </span>


            <span class="next pagination-item newer">
                <a href="../../data-visualization/01-visualization_fundamentals/" rel="next" title="Visualization Fundamentals">
Next post
              </a>
            </span>

        </div>

    </nav></aside><section class="comments hidden-print"><h2>Comments</h2>
                        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="chowygit",
            disqus_url="https://chow1026.github.io/course-notes/machine-learning/14-evaluation_metrics/",
        disqus_title="Evaluation Metrics",
        disqus_identifier="cache/course-notes/machine-learning/14-evaluation_metrics.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="chowygit";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>

    
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73098247-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
