<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title> =^..^= MEH · Course Notes (old posts, page 3) </title>
<link href="../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/poole.css" rel="stylesheet" type="text/css">
<link href="../assets/css/hyde.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700%7CAbril+Fatface">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="https://chowy1026.github.io/course-notes/index-3.html">
<link rel="icon" href="../images/favicon.png" sizes="64x64">
<link rel="icon" href="../images/icon_512x512.png" sizes="512x512">
<link rel="prev" href="index-4.html" type="text/html">
<link rel="next" href="index-2.html" type="text/html">
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: true
            },
            displayAlign: 'center', // Change this to 'left' to left equations.
            "HTML-CSS": {
                styles: {'.MathJax_Display': {"margin": 0}}
            }
        });
    </script><script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script><!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->
</head>
<body class="test">
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

    <div class="sidebar">
        <div class="container sidebar-sticky">
            <div class="sidebar-about">
              <h1>
                <a href="https://chowy1026.github.io/">
                      <h1 id="brand"><a href="https://chowy1026.github.io/" title=" =^..^= MEH" rel="home">

        <span id="blog-title"> =^..^= MEH</span>
    </a></h1>

                </a>
              </h1>
                <p class="lead"></p>

            </div>
                <nav id="menu" role="navigation" class="sidebar-nav"><a class="sidebar-nav-item" href="../posts/index.html">Articles</a>
        <a class="sidebar-nav-item" href="index.html">Course Notes</a>
        <a class="sidebar-nav-item" href="../links/index.html">Links</a>
        <a class="sidebar-nav-item" href="../books/index.html">Books</a>
        <a class="sidebar-nav-item" href="../archives/archives.html">Archives</a>
        <a class="sidebar-nav-item" href="../tags.html">Tags</a>
    
    
    </nav><footer id="footer"><p class="footer">
              <span class="icon_row">

                <a href="mailto:chowy1026@gmail.com">
                  <img class="social_icon" src="../images/envelope1.png" title="email" width="24"></a> ·
                <!--<a href="">
                  <img class="social_icon" src="/images/twitter-black-shape1.png" title="twitter" width="24" /></a> &middot;-->
                <a href="https://github.com/chowy1026/">
                  <img class="social_icon" src="../images/github-character1.png" title="github" width="24"></a>
              </span>
              <br><br><span class="copyright">
              
Contents © 2017 by <a href="mailto:chowy1026@gmail.com">cHoWy</a> ·
Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a> <br><a href="http://hyde.getpoole.com" target="_blank">Hyde</a> theme by <a href="https://twitter.com/mdo" target="_blank">@mdo</a>

            </span>
            </p>
            
        </footer>
</div>
    </div>

    <div class="content container" id="content">

<div class="sectionindex">
    <header><h2><a href=".">Course Notes (old posts, page 3)</a></h2>
    </header><div class="post">
    <article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="machine-learning/03-supervised_learning-decision_tree/" class="u-url">Supervised Learning - Decision Tree</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-04-03T17:14:29+08:00" title="2017-04-03 17:14">2017-04-03 17:14</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>A <a href="https://en.wikipedia.org/wiki/Decision_tree" title="Decision Tree">decision tree</a> is a <a href="https://en.wikipedia.org/wiki/Decision_support_system" title="Decision Support System">decision support</a> tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm.</p>
<p>Decision trees are commonly used in <a href="https://en.wikipedia.org/wiki/Operations_research" title="Operations Research">operations research</a>, specifically in <a href="https://en.wikipedia.org/wiki/Decision_analysis" title="Decision Analysis">decision analysis</a>, to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.</p>
<h2>Overview</h2>
<p>A decision tree is a <a href="https://en.wikipedia.org/wiki/Flowchart" title="Flowchart">flowchart</a>-like structure in which each internal node represents a "test" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.</p>
<p>In <a href="https://en.wikipedia.org/wiki/Decision_analysis" title="Decision Analysis">decision analysis</a>, a decision tree and the closely related <a href="https://en.wikipedia.org/wiki/Influence_diagram" title="Influence Diagram">influence diagram</a> are used as a visual and analytical decision support tool, where the expected values (or expected utility) of competing alternatives are calculated.</p>
<p>A decision tree consists of three types of nodes:</p>
<p>Decision nodes – typically represented by squares
Chance nodes – typically represented by circles
End nodes – typically represented by triangles
Decision trees are commonly used in operations research and <a href="https://en.wikipedia.org/wiki/Operations_management" title="Operation Management">operations management</a>. If, in practice, decisions have to be taken online with no recall under incomplete knowledge, a decision tree should be paralleled by a probability model as a best choice model or online selection model algorithm. Another use of decision trees is as a descriptive means for calculating <a href="https://en.wikipedia.org/wiki/Conditional_probability" title="Conditional Probability">conditional probabilities</a>.</p>
<p><a href="https://en.wikipedia.org/wiki/Decision_tree" title="Decision Tree">Decision trees</a>, <a href="https://en.wikipedia.org/wiki/Influence_diagram" title="Influence Diagram">influence diagrams</a>, <a href="https://en.wikipedia.org/wiki/Utility#Utility_functions" title="Utility Functions">utility functions</a>, and other decision analysis tools and methods are taught to undergraduate students in schools of business, health economics, and public health, and are examples of operations research or management science methods.</p>
<h2>Data Impurity and Entropy</h2>
<p>A decision tree is built top-down from a root node and involves partitioning the data into subsets that contain instances with similar values (homogenous). ID3 algorithm uses entropy to calculate the homogeneity of a sample. If the sample is completely homogeneous the entropy is zero and if the sample is an equally divided it has entropy of one.
\begin{aligned}
p &amp;= 0.5\\
\therefore\; q &amp;= 1 - p\\
&amp;= 0.5\\
\end{aligned}</p>
<p>\begin{aligned}
Entropy &amp;= -p\,log_2p -q\,log_2q\\
&amp;= -0.5\,log_20.5 -0.5\,log_20.5\\
&amp;= 1\\
\end{aligned}</p>
<p>To build a decision tree, we need to calculate two types of entropy using frequency tables as follows:   <br>
a) Entropy using the frequency table of one attribute:
\[
E(S) = - \sum_{i=1}^c\;p_i\,log_2(p_i)
\]
b) Entropy using the frequency table of two attributes:  <br>
\[
E(T,X) = - \sum_{c\in X}\;P(c)\,E(c)
\]</p>
<h2>Information Gain</h2>
<p>The information gain is based on the decrease in entropy after a dataset is split on an attribute. Constructing a decision tree is all about finding attribute that returns the highest information gain (i.e., the most homogeneous branches).    </p>
<p>Step 1: Calculate entropy of the target.    </p>
<p>Step 2: The dataset is then split on the different attributes. The entropy for each branch is calculated. Then it is added proportionally, to get total entropy for the split. The resulting entropy is subtracted from the entropy before the split. The result is the Information Gain, or decrease in entropy.    <br>
\begin{aligned}
Gain(T, X) &amp;= Entropy(T) - Entropy(T,X)\\
&amp;= E(T) - E(T,X)
\end{aligned}</p>
<p>Step 3: Choose attribute with the largest information gain as the decision node, divide the dataset by its branches and repeat the same process on every branch.     </p>
<p>Step 4a: A branch with entropy of 0 is a leaf node.     </p>
<p>Step 4b: A branch with entropy more than 0 needs further splitting.     </p>
<p>Step 5: The ID3 algorithm is run recursively on the non-leaf branches, until all data is classified.      </p>
<h2>Decision Tree Strengths and Weaknesses</h2>
<h3>Strengths</h3>
<ul>
<li>Easy to use,</li>
<li>Beautiful to draw/grow</li>
<li>Graphically describes the data</li>
<li>Bigger, custom classifiers can be built out of decision tree via ensemble methods.</li>
</ul>
<h3>Weaknesses</h3>
<ul>
<li>Prone to overfitting, esp too many features</li>
<li>
<h3>Needs to pay attention to tuning parameters, stop the growth of the tree (by tuning min samples split) at the appropriate time</h3>
</li>
</ul>
<h2>Other useful references:</h2>
<ul>
<li>[<a href="https://www.garysieling.com/blog/sklearn-gini-vs-entropy-criteria" title="Gini vs Entropy">Gini vs Entropy</a>]     </li>
<li>
<a href="http://www.saedsayad.com/decision_tree.htm" title="Decision Tree">Decision Tree</a> by Saed Sayad     </li>
<li>
<a href="http://scikit-learn.org/stable/modules/tree.html#tree" title="Scikit-Learn Decision Tree">Scikit-Learn Decision Tree</a>     </li>
<li>
<a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="Scikit-Learn Decision Tree Classifier">Scikit-Learn DT Classifier</a>     </li>
</ul>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="machine-learning/02-supervised_learning-svm/" class="u-url">Supervised Learning - Support Vector Machine (SVM)</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-04-03T10:11:55+08:00" title="2017-04-03 10:11">2017-04-03 10:11</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Support Vector Machine (SVM)</h2>
<p>In <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine Learning">machine learning</a>, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for <a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical Classification">classification</a> and <a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression Analysis">regression analysis</a>. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-<a href="https://en.wikipedia.org/wiki/Probabilistic_classification" title="Probabilistic Classification">probabilistic</a> <a href="https://en.wikipedia.org/wiki/Binary_classification" title="Binary Classification">binary</a> <a href="https://en.wikipedia.org/wiki/Linear_classifier" title="Linear Classifier">linear classifier</a>. An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.</p>
<p>In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.</p>
<p>When data are not labeled, supervised learning is not possible, and an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning" title="Unsupervised Learning">unsupervised learnin</a>g approach is required, which attempts to find natural <a href="https://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster Analysis">clustering of the data</a> to groups, and then map new data to these formed groups. The clustering algorithm which provides an improvement to the support vector machines is called support vector clustering and is often[citation needed] used in industrial applications either when data are not labeled or when only some data are labeled as a preprocessing for a classification pass.</p>
<h3>Motivation</h3>
<p><a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical Classification">Classifying data</a> is a common task in <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine Learning">machine learning</a>. Suppose some given data points each belong to one of two classes, and the goal is to decide which class a new data point will be in. In the case of support vector machines, a data point is viewed as a \( p \)-dimensional vector (a list of \( p \) numbers), and we want to know whether we can separate such points with a \( (p-1) \)-dimensional <a href="https://en.wikipedia.org/wiki/Hyperplane_separation_theorem" title="Hyperplane Separation Theorem">hyperplane</a>. This is called a linear classifier. There are many hyperplanes that might classify the data. One reasonable choice as the best hyperplane is the one that represents the largest separation, or <a href="https://en.wikipedia.org/wiki/Margin_(machine_learning)" title="Margin (Machine Learning)">margin</a>, between the two classes. So we choose the hyperplane so that the distance from it to the nearest data point on each side is maximized. If such a hyperplane exists, it is known as the maximum-margin hyperplane and the linear classifier it defines is known as a maximum <a href="https://en.wikipedia.org/wiki/Margin_classifier" title="Margin Classifier">margin classifier</a>; or equivalently, the <a href="https://en.wikipedia.org/wiki/Perceptron" title="Perceptron">perceptron</a> of optimal stability.</p>
<h3>Definition</h3>
<p>More formally, a support vector machine constructs a <a href="https://en.wikipedia.org/wiki/Hyperplane_separation_theorem" title="Hyperplane Separation Theorem">hyperplane</a> or set of hyperplanes in a high- or infinite-dimensional space, which can be used for classification, regression, or other tasks. Intuitively, a good separation is achieved by the hyperplane that has the largest distance to the nearest training-data point of any class (so-called functional margin), since in general the larger the margin the lower the <a href="https://en.wikipedia.org/wiki/Generalization_error" title="Generalization Error">generalization error</a> of the classifier.</p>
<p>Whereas the original problem may be stated in a finite dimensional space, it often happens that the sets to discriminate are not <a href="https://en.wikipedia.org/wiki/Linear_separability" title="Linear Separability">linearly separable</a> in that space. For this reason, it was proposed that the original finite-dimensional space be mapped into a much higher-dimensional space, presumably making the separation easier in that space. To keep the computational load reasonable, the mappings used by SVM schemes are designed to ensure that dot products may be computed easily in terms of the variables in the original space, by defining them in terms of a <a href="https://en.wikipedia.org/wiki/Positive-definite_kernel" title="Kernel Function">kernel function</a> \( k(x,y) \) k(x,y) selected to suit the problem.</p>
<h3>Applications</h3>
<p>SVMs can be used to solve various real world problems:</p>
<ul>
<li>SVMs are helpful in <a href="https://en.wikipedia.org/wiki/Document_classification" title="Text/Document Classification">text and hypertext categorization</a> as their application can significantly reduce the need for labeled training instances in both the standard inductive and <a href="https://en.wikipedia.org/wiki/Transduction_(machine_learning)" title="Transduction (Machine Learning)">transductive</a> settings.</li>
<li>
<a href="https://en.wikipedia.org/wiki/Computer_vision#Recognition" title="Image Recognition">Classification of images</a> can also be performed using SVMs. Experimental results show that SVMs achieve significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback. This is also true of <a href="https://en.wikipedia.org/wiki/Image_segmentation" title="Image Segmentation">image segmentation</a> systems, including those using a modified version SVM that uses the privileged approach as suggested by Vapnik.</li>
<li>
<a href="https://en.wikipedia.org/wiki/Handwriting_recognition" title="Handwriting Recognition">Hand-written characters can be recognized</a> using SVM.</li>
<li>The SVM algorithm has been widely applied in the biological and other sciences. They have been used to classify proteins with up to 90% of the compounds classified correctly. <a href="https://en.wikipedia.org/wiki/Resampling_(statistics)#Permutation_tests" title="Permutation Tests">Permutation tests</a> based on SVM weights have been suggested as a mechanism for interpretation of SVM models.  Support vector machine weights have also been used to interpret SVM models in the past.  Posthoc interpretation of support vector machine models in order to identify features used by the model to make predictions is a relatively new area of research with special significance in the biological sciences.</li>
</ul>
<h3>History</h3>
<p>The original SVM algorithm was invented by Vladimir N. Vapnik and Alexey Ya. Chervonenkis in 1963. In 1992, Bernhard E. Boser, Isabelle M. Guyon and Vladimir N. Vapnik suggested a way to create nonlinear classifiers by applying the <a href="https://en.wikipedia.org/wiki/Kernel_method" title="Kernel Trick">kernel trick</a> to maximum-margin hyperplanes.  The current standard incarnation (soft margin) was proposed by Corinna Cortes and Vapnik in 1993 and published in 1995.    </p>
<h2>Other Useful Resources</h2>
<ul>
<li>
<a href="http://scikit-learn.org/stable/modules/svm.html" title="Scikit-Learn SVM">Scikit-Learn Support Vector Machine</a>     </li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="Scikit-Learn Support Vector Classifier">Scikit-Learn Support Vector Classifier</a></li>
<li><a href="http://scikit-learn.org/stable/modules/svm.html#svm-classification" title="SVC User Guide">Scikit-Learn SVC User Guide</a></li>
<li><a href="http://scikit-learn.org/stable/modules/svm.html#svm-kernels" title="SVM Kernels">Scikit-Learn Kernel Functions</a></li>
</ul>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="machine-learning/01-supervised_learning-naive_bayes/" class="u-url">Supervised Learning - Naive Bayes</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-03-28T11:34:18+08:00" title="2017-03-28 11:34">2017-03-28 11:34</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Naive Bayes Classifier / Algorithm</h2>
<p>In <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine Learning">machine learning</a>, naive Bayes classifiers are a family of simple <a href="https://en.wikipedia.org/wiki/Probabilistic_classification" title="Probabilistic Classifier">probabilistic classifier</a>s based on applying <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" title="Bayes' Theorem">Bayes' theorem</a> with strong (naive) <a href="https://en.wikipedia.org/wiki/Independence_(probability_theory)" title="Independence Probability Theory">independence</a> assumptions between the features.</p>
<p>Naive Bayes has been studied extensively since the 1950s. It was introduced under a different name into the text retrieval community in the early 1960s, and remains a popular (baseline) method for text categorization, the problem of judging documents as belonging to one category or the other (such as spam or legitimate, sports or politics, etc.) with word frequencies as the features. With appropriate pre-processing, it is competitive in this domain with more advanced methods including support vector machines. It also finds application in automatic medical diagnosis.</p>
<p>Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" title="Maximum Likelihood Training">Maximum-likelihood training</a> can be done by evaluating a closed-form expression,[1]:718 which takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers.</p>
<p>In the statistics and computer science literature, Naive Bayes models are known under a variety of names, including simple Bayes and independence Bayes.  All these names reference the use of Bayes' theorem in the classifier's decision rule, but naive Bayes is not (necessarily) a Bayesian method.</p>
<p>Despite their naive design and apparently oversimplified assumptions, naive Bayes classifiers have worked quite well in many complex real-world situations. In 2004, an analysis of the Bayesian classification problem showed that there are sound theoretical reasons for the apparently implausible efficacy of naive Bayes classifiers.  Still, a comprehensive comparison with other classification algorithms in 2006 showed that Bayes classification is outperformed by other approaches, such as <a href="https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting" title="Boosted Trees">boosted trees</a> or <a href="https://en.wikipedia.org/wiki/Random_forest" title="Random Forests">random forests</a>.  </p>
<p>An advantage of naive Bayes is that it only requires a small number of training data to estimate the parameters necessary for classification.  </p>
<h3>Bayes Rules:</h3>
<p>Prior Probability * Test Evidence (in Probability) = Posterior Probability</p>
<p><strong>Cancer Example:</strong>       <br>
Prior Probabilities {Prior Cancer Probability is 1%}: <br>
\begin{aligned}
P(C) &amp;= 0.01\\
\therefore\; P(NC) &amp;= 1 - P(C)\\
&amp;= 0.99
\end{aligned}</p>
<p>Test Evidence, Sensitivity and Specificity Probabilities:    <br><em>Test Sensitivity</em>
\begin{aligned}
P(Pos|C) &amp;= 0.9\\
\therefore\; P(Neg|C) &amp;= 1 - 0.9\\
&amp;= 0.1 <br>
\end{aligned}</p>
<p><em>Test specificity</em>
\begin{aligned}
P(Neg|NC) &amp;= 0.9\\<br>
\therefore\; P(Pos|NC) &amp;= 1 - 0.9\\
&amp;= 0.1<br>
\end{aligned}</p>
<p>Joint Probability:   <br>
\begin{aligned}
P(C, Pos) &amp;= P(C) * P(Pos|C)\\
&amp;= 0.009\\\\
P(NC, Pos) &amp;= P(NC) * P(Pos|NC)\\
&amp;= 0.099\\\\
P(Pos) &amp;= P(C|Pos) + P(NC|Pos)\\
&amp;= 0.009 + 0.099 \\
&amp;= 0.108
\end{aligned}</p>
<p>Normalized Posterior Probability:
\begin{aligned}
P(C|Pos) &amp;= P(C, Pos) / P(Pos)\\
&amp;=  0.009 / 0.108\\
&amp;= 0.0833
\\\\
P(NC|Pos) &amp;= P(NC, Pos) / P(Pos)\\
&amp;=  0.099 / 0.108\\
&amp;= 0.9167
\end{aligned}</p>
<p>Legends:   <br>
- \(P(C)\): Prior Cancer Probability, in this case 1%
- \(P(NC)\): Prior non-Cancer Probability, 1-P(C), in this case 99%  <br>
- \(P(C, Pos)\): Joint probability that one having cancer AND tested positive   <br>
- \(P(NC, Pos)\): Joint probability that one does not have cancer AND tested positive    <br>
- \(P(C|Pos)\): Posterior probability of having cancer given one is tested positive   <br>
- \(P(NC|Pos)\): Posterior probability of NOT having cancer given one is tested positive   <br>
- \(P(Pos|C)\): Test sensitivity, Probability of tested positive if one has cancer   <br>
- \(P(Neg|NC)\): Test specificity, Probability of tested negative if one has NO cancer.</p>
<h3>Common Usage</h3>
<p>Naive Bayes is a pretty good algorithm for text learning.  Naive Bayes is called "Naive" because it works with <em>words</em> at various <em>length</em>, but ignores <em>word order</em>.    </p>
<h3>Pros:</h3>
<ul>
<li>Easy to implement      </li>
<li>Simple and efficient to run      </li>
<li>Big / Great feature spaces      </li>
</ul>
<h3>Cons:</h3>
<ul>
<li>It could break when phrases that encompasses multiple words that have distinctive meanings don't really work well.  For example Chicago Bulls will be interpreted as "Chicago" and "Bulls", but that's not what Chicago Bulls is.</li>
</ul>
<h2>Other references:</h2>
<ul>
<li><a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes" title="Scikit-Learn Naive Bayes">Scikit-Learn Naive Bayes</a></li>
<li>
<a href="http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html" title="Scikit-Learn Gaussian Naive Bayes">Scikit-Learn Gaussian Naive Bayes</a>    </li>
</ul>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="machine-learning/00-supervised_learning-introduction/" class="u-url">Supervised Learning - Introduction</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2017-03-26T14:25:23+08:00" title="2017-03-26 14:25">2017-03-26 14:25</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Supervised Learning and Classifications</h2>
<p><strong>Supervised learning</strong> is the machine learning task of inferring a function from labeled <em>training data</em>. The training data consist of a set of training examples. In supervised learning, each example is a <em>pair</em> consisting of an input object (typically a vector) and a desired output value (also called the <em>supervisory signal</em>). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see <a href="https://en.wikipedia.org/wiki/Inductive_bias" title="Inductive Bias">inductive bias</a>).</p>
<p>The parallel task in human and animal psychology is often referred to as <a href="https://en.wikipedia.org/wiki/Concept_learning" title="Concept Learning">concept learning</a>.</p>
<h3>Overview</h3>
<p>In order to solve a given problem of supervised learning, one has to perform the following steps:</p>
<ol>
<li>Determine the type of training examples. Before doing anything else, the user should decide what kind of data is to be used as a training set. In the case of handwriting analysis, for example, this might be a single handwritten character, an entire handwritten word, or an entire line of handwriting.      </li>
<li>Gather a training set. The training set needs to be representative of the real-world use of the function. Thus, a set of input objects is gathered and corresponding outputs are also gathered, either from human experts or from measurements.      </li>
<li>Determine the input feature representation of the learned function. The accuracy of the learned function depends strongly on how the input object is represented. Typically, the input object is transformed into a feature vector, which contains a number of features that are descriptive of the object. The number of features should not be too large, because of the <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" title="Curse of Dimensionality">curse of dimensionality</a>; but should contain enough information to accurately predict the output.       </li>
<li>Determine the structure of the learned function and corresponding learning algorithm. For example, the engineer may choose to use <a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support Vector Machine (SVM)">support vector machines</a> or <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision Tree">decision trees</a>.         </li>
<li>Complete the design. Run the learning algorithm on the gathered training set. Some supervised learning algorithms require the user to determine certain control parameters. These parameters may be adjusted by optimizing performance on a subset (called a validation set) of the training set, or via <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" title="Cross Validation">cross-validation</a>.          </li>
<li>Evaluate the accuracy of the learned function. After parameter adjustment and learning, the performance of the resulting function should be measured on a test set that is separate from the training set.          </li>
<li>A wide range of supervised learning algorithms are available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the <a href="https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization" title="No Free Lunch Theorem">No free lunch theorem</a>).     </li>
</ol>
<p>There are four major issues to consider in supervised learning:</p>
<h4>Bias-variance tradeoff</h4>
<p><em>Main article: <a href="https://en.wikipedia.org/wiki/Bias-variance_dilemma" title="Bias Variance Dilemma">Bias-variance dilemma</a></em>     </p>
<p>A first issue is the tradeoff between bias and variance. Imagine that we have available several different, but equally good, training data sets. A learning algorithm is biased for a particular input \( x \) if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for \( x \) . A learning algorithm has high variance for a particular input \( x \) if it predicts different output values when trained on different training sets. The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm. Generally, there is a tradeoff between bias and variance. A learning algorithm with low bias must be "flexible" so that it can fit the data well. But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance. A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance (either automatically or by providing a bias/variance parameter that the user can adjust).</p>
<h4>Function complexity and amount of training data</h4>
<p>The second issue is the amount of training data available relative to the complexity of the "true" function (classifier or regression function). If the true function is simple, then an "inflexible" learning algorithm with high bias and low variance will be able to learn it from a small amount of data. But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be learnable from a very large amount of training data and using a "flexible" learning algorithm with low bias and high variance.</p>
<h4>Dimensionality of the input space</h4>
<p>A third issue is the dimensionality of the input space. If the input feature vectors have very high dimension, the learning problem can be difficult even if the true function only depends on a small number of those features. This is because the many "extra" dimensions can confuse the learning algorithm and cause it to have high variance. Hence, high input dimensionality typically requires tuning the classifier to have low variance and high bias. In practice, if the engineer can manually remove irrelevant features from the input data, this is likely to improve the accuracy of the learned function. In addition, there are many algorithms for feature selection that seek to identify the relevant features and discard the irrelevant ones. This is an instance of the more general strategy of dimensionality reduction, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.</p>
<h4>Noise in the output values</h4>
<p>A fourth issue is the degree of noise in the desired output values (the supervisory target variables). If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples. Attempting to fit the data too carefully leads to overfitting. You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation that part of the target function that cannot be modeled "corrupts" your training data - this phenomenon has been called deterministic noise. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.</p>
<p>In practice, there are several approaches to alleviate noise in the output values such as early stopping to prevent overfitting as well as detecting and removing the noisy training examples prior to training the supervised learning algorithm. There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased generalization error with statistical significance.   </p>
<h4>Other factors to consider (important)</h4>
<p>Other factors to consider when choosing and applying a learning algorithm include the following:</p>
<ol>
<li>Heterogeneity of the data. If the feature vectors include features of many different kinds (discrete, discrete ordered, counts, continuous values), some algorithms are easier to apply than others. Many algorithms, including Support Vector Machines, linear regression, logistic regression, neural networks, and nearest neighbor methods, require that the input features be numerical and scaled to similar ranges (e.g., to the [-1,1] interval). Methods that employ a distance function, such as nearest neighbor methods and support vector machines with Gaussian kernels, are particularly sensitive to this. An advantage of decision trees is that they easily handle heterogeneous data.       </li>
<li>Redundancy in the data. If the input features contain redundant information (e.g., highly correlated features), some learning algorithms (e.g., linear regression, logistic regression, and distance based methods) will perform poorly because of numerical instabilities. These problems can often be solved by imposing some form of regularization.       </li>
<li>Presence of interactions and non-linearities. If each of the features makes an independent contribution to the output, then algorithms based on linear functions (e.g., linear regression, logistic regression, Support Vector Machines, naive Bayes) and distance functions (e.g., nearest neighbor methods, support vector machines with Gaussian kernels) generally perform well. However, if there are complex interactions among features, then algorithms such as decision trees and neural networks work better, because they are specifically designed to discover these interactions. Linear methods can also be applied, but the engineer must manually specify the interactions when using them.     </li>
<li>When considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see cross validation). Tuning the performance of a learning algorithm can be very time-consuming. Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.       </li>
</ol>
<p>The most widely used learning algorithms are <a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support Vector Machine (SVM)">Support Vector Machines</a>, <a href="https://en.wikipedia.org/wiki/Linear_regression" title="Linear Regression">linear regression</a>, <a href="https://en.wikipedia.org/wiki/Logistic_regression" title="Logistic Regression">logistic regression</a>, <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" title="Naive Bayes">naive Bayes</a>, <a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis" title="Linear Discriminant Analysis">linear discriminant analysis</a>, <a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision Tree">decision trees</a>, <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" title="K-Nearest Neighbors Algorithm">k-nearest neighbor algorithm</a>, and <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" title="Artificial Neural Network">Neural Networks</a> (<a href="https://en.wikipedia.org/wiki/Multilayer_perceptron" title="Multilayer Perceptron">Multilayer perceptron</a>).</p>
<p>In Machine learning, it is very important to train and test two different sets of data.  If we don't do that we could overfit the data.  We could think we know better what is actually going on than we actually know.</p>
<p>Usually when we get a dataset, we use 90% of the data as training data, and save 10% as testing data. When we do reporting, we use the results from the test data, as it more closely resemble real life application / tests on the algorithm.</p>
<h3>Overfitting and Underfitting</h3>
<p>In statistics and machine learning, one of the most common tasks is to fit a "model" to a set of training data, so as to be able to make reliable predictions on general untrained data.</p>
<p>In <strong>overfitting</strong>, a statistical model describes random error or noise instead of the underlying relationship. Overfitting occurs when a model is excessively complex, such as having too many parameters relative to the number of observations. A model that has been overfit has poor predictive performance, as it overreacts to minor fluctuations in the training data.</p>
<p><strong>Underfitting</strong> occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. Underfitting would occur, for example, when fitting a linear model to non-linear data. Such a model would have poor predictive performance.</p>
<p>The possibility of overfitting exists because the criterion used for training the model is not the same as the criterion used to judge the efficacy of a model. In particular, a model is typically trained by maximizing its performance on some set of training data. However, its efficacy is determined not by its performance on the training data but by its ability to perform well on unseen data. Overfitting occurs when a model begins to "memorize" training data rather than "learning" to generalize from trend. As an extreme example, if the number of parameters is the same as or greater than the number of observations, a simple model or learning process can perfectly predict the training data simply by memorizing the training data in its entirety, but such a model will typically fail drastically when making predictions about new or unseen data, since the simple model has not learned to generalize at all.</p>
<p>The potential for overfitting depends not only on the number of parameters and data but also the conformability of the model structure with the data shape, and the magnitude of model error compared to the expected level of noise or error in the data.</p>
<p>Even when the fitted model does not have an excessive number of parameters, it is to be expected that the fitted relationship will appear to perform less well on a new data set than on the data set used for fitting. In particular, the value of the coefficient of determination will shrink relative to the original training data.</p>
<p>In order to avoid overfitting, it is necessary to use additional techniques (e.g. <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" title="Cross Validation">cross-validation</a>, <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)" title="Regularization">regularization</a>, <a href="https://en.wikipedia.org/wiki/Early_stopping" title="Early Stopping">early stopping</a>, <a href="https://en.wikipedia.org/wiki/Pruning_(algorithm)" title="Pruning">pruning</a>, <a href="https://en.wikipedia.org/wiki/Prior_distribution" title="Bayesian Prior">Bayesian priors</a> on parameters or <a href="https://en.wikipedia.org/wiki/Bayesian_model_comparison" title="Bayesian Model Comparision">model comparison</a>), that can indicate when further training is not resulting in better generalization. The basis of some techniques is either (1) to explicitly penalize overly complex models, or (2) to test the model's ability to generalize by evaluating its performance on a set of data not used for training, which is assumed to approximate the typical unseen data that a model will encounter.</p>
<p>A good analogy for the overfitting problem is imagine a baby trying to learn what is a window or what is not a window, we start to show him windows and he detects at an initial phase that all windows have glasses, and a frame and you can look outside, some of them may be opened. If we keep showing the same windows the baby may also falsely deduce that all windows are green, and that all green frames are windows. Thus overfitting the problem.</p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="descriptive-statistics/final_project/" class="u-url">Descriptive Statistics Final Project - Random Draws of Card Deck</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-14T11:39:38+08:00" title="2016-11-14 11:39">2016-11-14 11:39</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Instead of working on this project on a google sheet files, I decided to write my own python script to simulate the experiments.  </p>
<p>1) Histogram generated shown as below.   <br><img alt="Original Cards" src="../images/descriptive-statistics/original52.png"><br>
Histogram for original card values are negatively skewed (towards right).    </p>
<p>2) Randomly Drawing 3 Cards   <br>
I wrote python scripts with pandas and matplotlib for the rest of the project.  </p>
<p>3) Distribution of Sum of 3 Randomly Drawn Cards   <br><strong>30 Samples of Sum of 3 Randomly Drawn Cards</strong>   <br><img alt="30 Samples of Sum of 3 Randomly Drawn Cards" src="../images/descriptive-statistics/sample30.png"></p>
<p>Statistical Description of this sample with n = 30:  <br>
count  30.000000  <br>
mean   19.866667  <br>
std     5.550603  <br>
min     9.000000  <br>
25%    15.000000  <br>
50%    20.000000  <br>
75%    24.000000  <br>
max    30.000000    </p>
<p><strong>500 Samples of Sum of 3 Randomly Drawn Cards</strong>      <br><img alt="500 Samples of Sum of 3 Randomly Drawn Cards" src="../images/descriptive-statistics/sample500.png"></p>
<p>Statistical Description of this sample with n = 500:  <br>
count  500.000000  <br>
mean    19.542000  <br>
std      5.337529  <br>
min      5.000000  <br>
25%     16.000000  <br>
50%     20.000000  <br>
75%     24.000000  <br>
max     30.000000    </p>
<p>4) As sample size increases, the curve gets more normalized (bell-shaped).     </p>
<p>5) Q:  Within what range will you expect approximately 90% of your draw values to fall? What is the approximate probability that you will get a draw value of at least 20? Make sure you justify how you obtained your values.    </p>
<p>To determine the range where 90% of the values fall, I found the closest corresponding z-value to be 1.28.   Therefore, with the following formula, I determined the range for our sample with 30 draws, and sample with 500 draws.   </p>
<p>\[<br>
  z = \frac{ x - \mu }{\sigma} \\
  x_{30, 90%} = 26.971442   \\
  x_{500, 90%} = 26.374   \\
\]  </p>
<p>To draw at least 20 from each of the samples, the corresponding z values are:    </p>
<p>\[
  z_{30, &gt;20} = \frac{20 - 19.866667}{5.550603} = 0.024021
  \\
  z_{500, &gt;20} = \frac{20 - 19.542000}{5.337529} = 0.085807 \\
\]</p>
<p>For sample with sample size 30, at z = 0.024021, the probability is 0.51 (51%).  That means the change of drawing 3 cards with sum greater than 20 from this sample is 49%.      </p>
<p>For sample with sample size 500, at z = 0.024021, the probability is 0.534 (53.4%).  That means the change of drawing 3 cards with sum greater than 20 from this sample is 46.6%.    </p>
<p>Finally, here's a <a href="http://www.stat.ufl.edu/~athienit/Tables/Ztable.pdf">link to the z-table</a> for reference.  </p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="inferential-statistics/lesson-16/" class="u-url">Inferential Statistics - Chi-Squared Tests</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-09T13:10:55+08:00" title="2016-11-09 13:10">2016-11-09 13:10</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h3>Types of Data</h3>
<ul>
<li>
<strong>Ordinal Data</strong> - ranks with no fixed intervals nor zeros   </li>
<li>
<strong>Interval Data</strong> - ranks with equal intervals     </li>
<li>
<strong>Ratio Data</strong> - ranks with equal intervals and an absolute zero   </li>
<li>
<strong>Nominal/Categorical Data</strong> - data with no numerical values (typically yes/no, in/out, successful/unsuccessful)    </li>
</ul>
<h3>Types of Tests</h3>
<ul>
<li>
<strong>Parametric</strong> - hypothesis testing that make assumptions about the parameters of the populations, \( \mu \) and \( \sigma \).</li>
<li>
<strong>Non-Parametric</strong> - hypothesis testing that do not require population parameters</li>
</ul>
<h3>Characteristics of Non-Parametric Testings</h3>
<ul>
<li>There is no way to calculate a mean or standard deviation      </li>
<li>The data is based on frequencies or proportions    </li>
<li>The data is nominal (successful vs unsuccessful, 1 or 0, yes or no, mountain vs beach etc.)    </li>
<li>The data are not based on Normal distribution    </li>
</ul>
<h3>\( \chi^2 \) Goodness of Fit Test</h3>
<p>How well our observed frequencies 'fit' our expected frequencies? <br>
\[
  \chi ^2 = \sum{ \frac{(f_0 - f_e)^2}{f_e} }
\]
\( \chi^2 \) is smaller when the observed value is closer to the expected value.   <br>
\( \chi^2 \) is NEVER negative and therefore \( \chi^2 \) statistic is one-directional.     </p>
<p>For each category, we have one \( \chi^2 \) statistics.  When we have more categories, \( \chi^2 \) statistics get bigger with the number of categories.    </p>
<h3>Degrees of Freedom</h3>
<p>For n x m, 2 dimensional nominal data:
\[
  df = (N_n - 1) * (N_m - 1) \\
  \text{where } N_n \text{ and }N_m \text{ are number of columns, and number of rows respectively. }
\]</p>
<h3>Cramer's V \( (\phi_c) \)</h3>
<p>\[
  \phi_c = \sqrt{\frac{\chi^2}{n(k-1)}}  \\
  k \text{ is the smaller number between number of rows or number of columns}\\
  n \text{ is the total sample size regardless of treatments}
\]</p>
<h3>Assumptions and Restrictions for \(\chi^2\) Tests</h3>
<ul>
<li>Avoid dependent observations.  Independence will be violated if any participants were given two treatments instead of one.     </li>
<li>Avoid small expected frequencies, therefore in general have a larger number of participants.   Sample size should be at least 20, and each expected cell frequencies should be at least 5.    </li>
</ul>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="inferential-statistics/lesson-15/" class="u-url">Inferential Statistics - Regressions</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-08T15:00:58+08:00" title="2016-11-08 15:00">2016-11-08 15:00</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h3>Linear Regressions</h3>
<p>Line of best fit forms a line to help us:  <br>
- describe data  <br>
- make predictions     </p>
<p><strong>Observed Y vs Expected Y</strong>   <br><strong>Expected Y</strong> \( \hat{y} \) are the ones calculated/predicted based on the best fit regression line.  <br><strong>Observed Y</strong> \( y \) are collected data or real-life data.  <br><strong>Residual</strong> is the difference between Observed value and Expected value.  </p>
<p>A few ways to find the line of best fit:  <br>
- Find a line to minimize the sum of residuals.   The problem with this approach is sometimes, negative and positive residuals cancel each other out.     <br>
- Find a line that minimize the sum of <strong>absolute</strong> residuals.  <br>
- Find a line that minimize the sum of squared residuals, \( \sum{(y - \hat{y})} \)</p>
<p>When we use calculus to determine the slope, b:<br>
\[
  b = \frac{\sum{(y_i - \bar{y})(x_i - \bar{x})}}{\sum{(x_i - \bar{x})^2}} \\
  = r (\frac{S_y}{S_x}) \\
  \text{where } r \text{ is Pearson's Correlation Coefficient and }\\
   S \text{ are standard deviations of } x \text{ and } y.
\]</p>
<p>We have decided to symbolize the regression line by y = bx + a, where b represents the slope and a represents the y-intercept.
Since \( b = r(\frac{S_y}{S_x}) \), we can also symbolize the regression line like this:  <br>
\[ y = r(\frac{S_y}{S_x})x + a \]</p>
<p><strong>Pearson's Correlation Coefficient \( r \)</strong>  <br>
A high \(r\) value indicates a strong correlation. This could contribute to high \(r^2 \) value, which indicates the percentage of differences in Y is due to differences in X.  </p>
<p><strong>Standard Error of Estimates</strong>  <br>
Standard error of estimates: <br>
\[
SE = \sqrt{ \frac{\sum (y - \hat{y})^2}{N-2}}
\]</p>
<p><strong>Factors that Affect the Regressions</strong> <br>
- outliers affect the value of r, correlation Coefficient
- outliers also affect the linear regression line
-</p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="inferential-statistics/lesson-14/" class="u-url">Inferential Statistics - Correlations</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-07T13:33:58+08:00" title="2016-11-07 13:33">2016-11-07 13:33</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p><strong>Relationships</strong>   <br>
How one variable is related to the other?</p>
<p><strong>Variable X and Y</strong>    <br>
X is often referred to as the predictor, explanatory, independent variable.      </p>
<p>Y is often referred as the outcome, response, dependent variable.  </p>
<p>Scatterplot is a popular/ most common way to show relationship of X and Y variables.      </p>
<p><strong>Strong Relationships</strong>    <br>
Strong relationships usually have less scattered plots.  If we draw an eclipse surrounding the data points, the smaller the ratio of minor axis to the major axis, the stronger the relationship is.  </p>
<p><strong>Direction of Relationships</strong>       <br>
Positively related - Y responses in the same direction as X changes; Negatively related - Y responses in opposite directions of X changes.</p>
<p><strong>Correlation Coefficient, (r)</strong>    <br>
Also known as Pierson's r.  </p>
<p>r is a fraction, with the covariance of x and y (how much do they vary together) as the numerator, and the product of standard deviation of x  and standard deviation of y as the denominator.<br>
\[
  r = \frac{cov(x,y)}{ S_x * S_y } = \frac{cov_{x,y}}{ S_x * S_y }
\]  <br>
r measures the strength of a relationship, by measuring how closely the data falls along a straight line.      </p>
<p>Even though r is a ratio, it is not interpreted as a percentage.  However, \(r^2\) is a percentage of the variation in y explained by variation in x.  \(r^2\) is called the coefficient determination.       </p>
<p><strong>True Correlation of Population, rho, \( \rho \)</strong>     <br>
We usually perform hypothesis testing with t-tests.
\[
  H_{0} : \rho = 0 \\
  H_{1} : \rho \gt 0 \\
  H_{1} : \rho \lt 0 \\
  H_{1} : \rho \ne 0
\]</p>
<p><strong>Causation vs Correlations</strong>    <br><strong>Causation</strong> - One variable caused another to happen.     </p>
<p><strong>Correlation</strong> - There is a relationship between two variables.  But there are lots of lurking variables.  For example, there are two variables X and Y.  They could have a relationship because both of them are influenced by variable A, or Y is influenced by X <strong>through</strong> variable A.  In this case, variable A is called the mediating variable.  </p>
<p>To make a causal statement: <br>
     - the independent variable would have to occur BEFORE the dependent variable.<br>
     - have to rule out other lurking variables too</p>
<p><strong>Fallacies</strong>  <br>
Ambiguous Temporal Precedence - we don't know which variable happens first.   <br>
Third variable problem    <br>
Post-hoc fallacy      </p>
<p><strong>t value and Correlation Coefficient, (r)</strong>   <br>
t value and r:
\[
  t = \frac{r  \sqrt{N-2}}{\sqrt{1-r^2}}
\]
where \(df\) is \( N - 2 \)</p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="inferential-statistics/lesson-13/" class="u-url">Inferential Statistics - ANOVA Continued.</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-11-03T21:55:35+08:00" title="2016-11-03 21:55">2016-11-03 21:55</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>One of the popular Multiple Comparison Tests is Tukey's Honestly Significant Differences.    <br><strong>Tukey's Honestly Significant Differences (HSD)</strong>  <br>
Tukey's HSD is calculated as the following:
\[
\text{Tukey's HSD} = q * \sqrt{\frac{MS_{within}}{n}} \\
q \text{ is looked up with } df_{within} \text{ and } k \text{, the number of treatments/sample groups}   \\
n \text{ is the number of samples in one sample group}
\]   </p>
<p>If the mean difference between/among treatments are greater than Tukey's HSD, the difference is significant.    </p>
<p>Note this is very similar to Z test and T test. For Z tests, the margin of error is:
\[
\text{Margin of Error} = z * \frac{\sigma}{\sqrt{n}}
\]</p>
<p>Whereas for t tests, the margin of error is:
\[
\text{Margin of Error} = t * \frac{s}{\sqrt{n}}
\]</p>
<p><strong>Cohen's D for Multiple Comparisons</strong>  <br>
For normal comparisons, Cohen's D is calculated by
\[
\text{Cohen's D, } d = \frac{\bar{X_1} - \bar{X_2}}{SD_{pooled}}
\]   </p>
<p>In multiple comparisons, Cohen's D is calculated by
\[
\text{Cohen's D, } d = \frac{\bar{X_1} - \bar{X_2}}{\sqrt{MS_{within}}}
\]</p>
<p>Cohen's D is calculated per pair comparisons.  </p>
<p><strong>\( \mathbf{\eta ^ 2} \)</strong>  <br>
\( \eta ^2 \) is defined as the proportion of total variance that is due to between-group differences (explained variation).  </p>
<p>\[
\eta ^2 = \frac{SS_{between}}{SS_{total}} \\
      = \frac{SS_{between}}{SS_{between} + SS_{within}}
\]    </p>
<p><strong>Reporting Reports of Anova</strong>  <br>
We report the results of F Statistics as the following:   <br>
\[
   F(df_{between}, df_{within}) = 27 \quad p &lt; 0.05 \quad \eta ^2 = 0.90 \quad \\
   \text{p is estimated, by hand} \\
   F(df_{between}, df_{within}) = 27 \quad p = 0.001 \quad \eta ^2 = 0.90 \quad \\
   \text{exact p value calculated by software} \\
\]</p>
<p><strong>ANOVA for Groups with Different Sample Sizes</strong>  <br>
Grand mean
\[
  \text{Grand mean, } \bar{X_G} = \frac{ \sum_{j=0}^k n_j (\bar{x_j}) }{\sum_{j=0}^k n_j } \\
  n_j \text{ is sample size for each sample} \\<br>
  k \text{ is number of sample groups}      \\
\]    </p>
<p>SS (Sum of Squares) Between   <br>
\[
  \text{sum of squares, } SS_{between} = \sum_{j=0}^k n_j (\bar{x_j} - \bar{x_G})^2 \\
  n_j \text{ is sample size for each sample}   \\
\]    </p>
<p>SS (Sum of Squares) Within   <br>
\[
  \text{sum of squares, } SS_{within} = \sum_{i=0}^N (x_i - \bar{x_k})^2 \\
  k \text{ is number of sample groups}      \\
  N \text{ is total number of all samples of each sample group}     \\
\]    </p>
<p>DF (Degress of Freedom) Between   <br>
\[
  \text{degrees of freedom, } df_{between} = k - 1 \\
  k \text{ is number of sample groups}    \\
\]    </p>
<p>DF (Degress of Freedom) Within   <br>
\[
  \text{degrees of freedom, } df_{within} = N - k \\
  k \text{ is number of sample groups}      \\
  N \text{ is total number of all samples of each sample group}     \\
\]    </p>
<p>MS (Mean Squares) Between   <br>
\[
  \text{Mean square, } MS_{between} = \frac{SS_{between}}{df_{between}}  \\
  = \frac{\sum_{j=0}^k n_j (\bar{x_j} - \bar{x_G})^2}{k - 1}
\]    </p>
<p>MS (Mean Squares) Within   <br>
\[
\text{Mean square, } MS_{within} = \frac{SS_{within}}{df_{within}}  \\
= \frac{\sum_{i=0}^N (x_i - \bar{x_k})^2}{N - k}
\]    </p>
<p>F Stats
\[
\text{F Statistics, } F = \frac{MS_{between}}{MS_{within}}  \\
= \frac{\sum_{j=0}^k n_j (\bar{x_j} - \bar{x_G})^2 / (k - 1)}{\sum_{i=0}^N (x_i - \bar{x_k})^2 / (N - k)}
\]   </p>
<p><strong>\( \mathbf{\eta ^ 2} \)</strong><br>
\[
\eta ^2 = \frac{SS_{between}}{SS_{total}} \\
      = \frac{SS_{between}}{SS_{between} + SS_{within}}
\]  </p>
<p><strong>ANOVA Power</strong>  <br>
Increase POWER in order to avoid Type II statistical error where we fail to reject the null when there is a treatment effect.   </p>
<p>In the case of drug testing, we want to:  <br>
- test <strong>more people</strong>  <br>
- give each drug to <strong>very similar</strong> groups of people  <br>
- test with a <strong>strong</strong> dosage    </p>
<p><strong>ANOVA Assumptions &amp; Conclusions</strong>   <br>
We assume:  <br>
- <strong>Normality</strong>: the population of which our samples are from are all normally distributed.  <br>
- <strong>Homogeneity of Variance</strong>: the samples come from populations that have equal amount of variability.   <br>
- <strong>Independence of Observations</strong>: The results found from one samples won't affect the others.   </p>
<p>We could have the following exceptions:  <br>
- violate the normality if the sample is large  <br>
- violate the homogeneity of variance if:  <br>
        - almost equal sample sizes  <br>
        - ratio of any two variances doesn't exceed 4     <br>
-</p>
</div>
    </div>
    </article><article class="post h-entry post-text"><header><h1 class="post-title p-name"><a href="intro-data-analysis/1-data_analysis_process/" class="u-url">Intro to DA - Data Analysis Process</a></h1>
        <div class="metadata">
            <span class="post-date dateline"><time class="published dt-published" datetime="2016-10-14T13:57:55+08:00" title="2016-10-14 13:57">2016-10-14 13:57</time></span>
        </div>
    </header><div class="e-content entry-content">
    <div>
<h2>Data Analysis Process</h2>
<ol>
<li>
<strong>Question</strong>  <br>
    Problem begins with a question you want answer or problem you wanna solve.  For example:    <ul>
<li>Characters of students who pass projects</li>
<li>How can I stock stores with products that most people want to buy?</li>
</ul>
</li>
<li>
<strong>Wrangler</strong>    <ul>
<li>Data Acquisition   </li>
<li>Data Cleaning   </li>
</ul>
</li>
<li>
<strong>Explore</strong>   <ul>
<li>Building intuition</li>
<li>Finding patterns</li>
</ul>
</li>
<li>
<strong>Draw Conclusions</strong>   <br>
    This requires statistics and machine learning (that is beyond the scope of this course)<ul>
<li>Draw Conclusion =&gt; Users less likely to XXX</li>
<li>Make Prediction =&gt; Predict what products a user would like</li>
</ul>
</li>
<li>
<strong>Communicate</strong>  <ul>
<li>Blog post, paper, email, powerpoint, in-person conversation</li>
</ul>
</li>
</ol>
<p>The steps aren't always sequential.  We might go back and forth between data wrangling and exploration.  Along the process, one may go back to the question to further refine the question.  And data acquisition might occur before the question arises.</p>
<h2>Data Wrangling</h2>
<p>Data Types: <br>
Usually data acquired are in JSON or CSV (comma separated value) format.    </p>
</div>
    </div>
    </article>
</div>
        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-4.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-2.html" rel="next">Older posts</a>
            </li>
        </ul></nav><script>var disqus_shortname="chowygit";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>

    </div>

    
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73098247-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
